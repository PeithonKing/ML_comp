# -*- coding: utf-8 -*-
"""Predictum_Transfer_Inception.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eYoQdiSYP93wl_v7JsxUYyUEpTem_hAw
"""

print("\n\nImporting")
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import Model
print("\nImported\n")

# !unrar x "/content/drive/MyDrive/ML4SCI_Gravitational_Lensing/Competition/datasetjpgrgb.rar" "/content/drive/MyDrive/ML4SCI_Gravitational_Lensing/Competition/"

# from google.colab import drive
# drive.mount('/content/drive')
# path = "/content/drive/MyDrive/ML4SCI_Gravitational_Lensing/Competition/"


from tensorflow.keras.applications.inception_v3 import InceptionV3

local_weights_file = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'

pre_trained_model = InceptionV3(input_shape = (150, 150, 3),
    include_top = False,
    weights = None)

pre_trained_model.load_weights(local_weights_file)

for layer in pre_trained_model.layers:
  layer.trainable = False

pre_trained_model.summary()

last_layer = pre_trained_model.get_layer('mixed7')
print('last layer output shape: ', last_layer.output_shape)
last_output = last_layer.output

# Flatten the output layer to 1 dimension
x = tf.keras.layers.Flatten()(last_output)
# Add a fully connected layer with 1,024 hidden units and ReLU activation
x = tf.keras.layers.Dense(1024, activation='relu')(x)
# Add a dropout rate of 0.2
x = tf.keras.layers.Dropout(0.2)(x)
# Add a final sigmoid layer for classification
x = tf.keras.layers.Dense  (3, activation='softmax')(x)

model = Model( pre_trained_model.input, x)

model.compile(
    optimizer=tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.95,
    beta_2=0.999,
    epsilon=1e-07
),
    loss='CategoricalCrossentropy',
    metrics=['AUC',"accuracy"]
)

train_datagen= ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
        'datasetjpgrgb/train',
        target_size=(150, 150),
        color_mode='rgb',
        batch_size=128,
        class_mode='categorical')
validation_generator = test_datagen.flow_from_directory(
        'datasetjpgrgb/val',
        target_size=(150, 150),
        color_mode='rgb',
        batch_size=1000,
        class_mode='categorical')

model.summary()


print("main part")
model.fit(
        train_generator,
        steps_per_epoch=80,
        epochs=500,
        validation_data=validation_generator,
        validation_steps=3)
