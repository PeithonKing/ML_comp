{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dbe6d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4157437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data=pd.read_csv(\"DataSetNormalised.csv\")\n",
    "df_label=pd.read_csv(\"LabelSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91dd774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(df_data.iloc[:,1:])\n",
    "y=np.array(df_label.iloc[:,1])\n",
    "x=x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206ac221",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x[:10000000][:]\n",
    "y_train=y[:10000000][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ea9b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_alpha=x[:10000000][:]\n",
    "y_train_alpha=y[:10000000][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ef3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x[10000000:][:]\n",
    "y_test=y[10000000:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffe909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_alpha=x[10000000:11000000][:]\n",
    "y_test_alpha=y[10000000:11000000][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "323dedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain=xgb.DMatrix(x_train_alpha, label=y_train_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388cbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest=xgb.DMatrix(x_test_alpha, label=y_test_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff07f7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000000, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebc26bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'booster':'dart',\n",
    "        'min_child_weight': 1,\n",
    "        'gamma': 0,\n",
    "        'subsample': 1,\n",
    "        'colsample_bytree': 1,\n",
    "        'max_depth': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b82cc621",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.28168\n",
      "[1]\tvalidation_0-error:0.27325\n",
      "[2]\tvalidation_0-error:0.26869\n",
      "[3]\tvalidation_0-error:0.26536\n",
      "[4]\tvalidation_0-error:0.26295\n",
      "[5]\tvalidation_0-error:0.26077\n",
      "[6]\tvalidation_0-error:0.25904\n",
      "[7]\tvalidation_0-error:0.25704\n",
      "[8]\tvalidation_0-error:0.25639\n",
      "[9]\tvalidation_0-error:0.25514\n",
      "[10]\tvalidation_0-error:0.25441\n",
      "[11]\tvalidation_0-error:0.25341\n",
      "[12]\tvalidation_0-error:0.25267\n",
      "[13]\tvalidation_0-error:0.25195\n",
      "[14]\tvalidation_0-error:0.25132\n",
      "[15]\tvalidation_0-error:0.25066\n",
      "[16]\tvalidation_0-error:0.25017\n",
      "[17]\tvalidation_0-error:0.25006\n",
      "[18]\tvalidation_0-error:0.24942\n",
      "[19]\tvalidation_0-error:0.24911\n",
      "[20]\tvalidation_0-error:0.24841\n",
      "[21]\tvalidation_0-error:0.24812\n",
      "[22]\tvalidation_0-error:0.24776\n",
      "[23]\tvalidation_0-error:0.24740\n",
      "[24]\tvalidation_0-error:0.24717\n",
      "[25]\tvalidation_0-error:0.24700\n",
      "[26]\tvalidation_0-error:0.24665\n",
      "[27]\tvalidation_0-error:0.24637\n",
      "[28]\tvalidation_0-error:0.24629\n",
      "[29]\tvalidation_0-error:0.24621\n",
      "[30]\tvalidation_0-error:0.24587\n",
      "[31]\tvalidation_0-error:0.24568\n",
      "[32]\tvalidation_0-error:0.24554\n",
      "[33]\tvalidation_0-error:0.24529\n",
      "[34]\tvalidation_0-error:0.24512\n",
      "[35]\tvalidation_0-error:0.24461\n",
      "[36]\tvalidation_0-error:0.24455\n",
      "[37]\tvalidation_0-error:0.24451\n",
      "[38]\tvalidation_0-error:0.24444\n",
      "[39]\tvalidation_0-error:0.24417\n",
      "[40]\tvalidation_0-error:0.24404\n",
      "[41]\tvalidation_0-error:0.24396\n",
      "[42]\tvalidation_0-error:0.24393\n",
      "[43]\tvalidation_0-error:0.24390\n",
      "[44]\tvalidation_0-error:0.24374\n",
      "[45]\tvalidation_0-error:0.24368\n",
      "[46]\tvalidation_0-error:0.24362\n",
      "[47]\tvalidation_0-error:0.24355\n",
      "[48]\tvalidation_0-error:0.24340\n",
      "[49]\tvalidation_0-error:0.24331\n",
      "[50]\tvalidation_0-error:0.24327\n",
      "[51]\tvalidation_0-error:0.24306\n",
      "[52]\tvalidation_0-error:0.24294\n",
      "[53]\tvalidation_0-error:0.24279\n",
      "[54]\tvalidation_0-error:0.24285\n",
      "[55]\tvalidation_0-error:0.24288\n",
      "[56]\tvalidation_0-error:0.24277\n",
      "[57]\tvalidation_0-error:0.24276\n",
      "[58]\tvalidation_0-error:0.24279\n",
      "[59]\tvalidation_0-error:0.24275\n",
      "[60]\tvalidation_0-error:0.24272\n",
      "[61]\tvalidation_0-error:0.24277\n",
      "[62]\tvalidation_0-error:0.24259\n",
      "[63]\tvalidation_0-error:0.24252\n",
      "[64]\tvalidation_0-error:0.24242\n",
      "[65]\tvalidation_0-error:0.24220\n",
      "[66]\tvalidation_0-error:0.24236\n",
      "[67]\tvalidation_0-error:0.24233\n",
      "[68]\tvalidation_0-error:0.24218\n",
      "[69]\tvalidation_0-error:0.24212\n",
      "[70]\tvalidation_0-error:0.24201\n",
      "[71]\tvalidation_0-error:0.24175\n",
      "[72]\tvalidation_0-error:0.24160\n",
      "[73]\tvalidation_0-error:0.24157\n",
      "[74]\tvalidation_0-error:0.24163\n",
      "[75]\tvalidation_0-error:0.24167\n",
      "[76]\tvalidation_0-error:0.24171\n",
      "[77]\tvalidation_0-error:0.24169\n",
      "[78]\tvalidation_0-error:0.24166\n",
      "[79]\tvalidation_0-error:0.24160\n",
      "[80]\tvalidation_0-error:0.24160\n",
      "[81]\tvalidation_0-error:0.24172\n",
      "[82]\tvalidation_0-error:0.24173\n",
      "[83]\tvalidation_0-error:0.24161\n",
      "[84]\tvalidation_0-error:0.24131\n",
      "[85]\tvalidation_0-error:0.24143\n",
      "[86]\tvalidation_0-error:0.24126\n",
      "[87]\tvalidation_0-error:0.24132\n",
      "[88]\tvalidation_0-error:0.24124\n",
      "[89]\tvalidation_0-error:0.24126\n",
      "[90]\tvalidation_0-error:0.24111\n",
      "[91]\tvalidation_0-error:0.24114\n",
      "[92]\tvalidation_0-error:0.24111\n",
      "[93]\tvalidation_0-error:0.24109\n",
      "[94]\tvalidation_0-error:0.24110\n",
      "[95]\tvalidation_0-error:0.24105\n",
      "[96]\tvalidation_0-error:0.24110\n",
      "[97]\tvalidation_0-error:0.24106\n",
      "[98]\tvalidation_0-error:0.24097\n",
      "[99]\tvalidation_0-error:0.24087\n",
      "[100]\tvalidation_0-error:0.24086\n",
      "[101]\tvalidation_0-error:0.24087\n",
      "[102]\tvalidation_0-error:0.24091\n",
      "[103]\tvalidation_0-error:0.24090\n",
      "[104]\tvalidation_0-error:0.24089\n",
      "[105]\tvalidation_0-error:0.24089\n",
      "[106]\tvalidation_0-error:0.24087\n",
      "[107]\tvalidation_0-error:0.24085\n",
      "[108]\tvalidation_0-error:0.24059\n",
      "[109]\tvalidation_0-error:0.24066\n",
      "[110]\tvalidation_0-error:0.24066\n",
      "[111]\tvalidation_0-error:0.24073\n",
      "[112]\tvalidation_0-error:0.24077\n",
      "[113]\tvalidation_0-error:0.24082\n",
      "[114]\tvalidation_0-error:0.24077\n",
      "[115]\tvalidation_0-error:0.24074\n",
      "[116]\tvalidation_0-error:0.24062\n",
      "[117]\tvalidation_0-error:0.24072\n",
      "[118]\tvalidation_0-error:0.24078\n",
      "[119]\tvalidation_0-error:0.24082\n",
      "[120]\tvalidation_0-error:0.24093\n",
      "[121]\tvalidation_0-error:0.24098\n",
      "[122]\tvalidation_0-error:0.24088\n",
      "[123]\tvalidation_0-error:0.24092\n",
      "[124]\tvalidation_0-error:0.24087\n",
      "[125]\tvalidation_0-error:0.24087\n",
      "[126]\tvalidation_0-error:0.24098\n",
      "[127]\tvalidation_0-error:0.24095\n",
      "[128]\tvalidation_0-error:0.24080\n",
      "[129]\tvalidation_0-error:0.24079\n",
      "[130]\tvalidation_0-error:0.24088\n",
      "[131]\tvalidation_0-error:0.24090\n",
      "[132]\tvalidation_0-error:0.24085\n",
      "[133]\tvalidation_0-error:0.24069\n",
      "[134]\tvalidation_0-error:0.24081\n",
      "[135]\tvalidation_0-error:0.24086\n",
      "[136]\tvalidation_0-error:0.24081\n",
      "[137]\tvalidation_0-error:0.24074\n",
      "[138]\tvalidation_0-error:0.24070\n",
      "[139]\tvalidation_0-error:0.24068\n",
      "[140]\tvalidation_0-error:0.24067\n",
      "[141]\tvalidation_0-error:0.24070\n",
      "[142]\tvalidation_0-error:0.24072\n",
      "[143]\tvalidation_0-error:0.24073\n",
      "[144]\tvalidation_0-error:0.24077\n",
      "[145]\tvalidation_0-error:0.24067\n",
      "[146]\tvalidation_0-error:0.24071\n",
      "[147]\tvalidation_0-error:0.24073\n",
      "[148]\tvalidation_0-error:0.24062\n",
      "[149]\tvalidation_0-error:0.24057\n",
      "[150]\tvalidation_0-error:0.24058\n",
      "[151]\tvalidation_0-error:0.24060\n",
      "[152]\tvalidation_0-error:0.24054\n",
      "[153]\tvalidation_0-error:0.24053\n",
      "[154]\tvalidation_0-error:0.24055\n",
      "[155]\tvalidation_0-error:0.24061\n",
      "[156]\tvalidation_0-error:0.24046\n",
      "[157]\tvalidation_0-error:0.24042\n",
      "[158]\tvalidation_0-error:0.24046\n",
      "[159]\tvalidation_0-error:0.24037\n",
      "[160]\tvalidation_0-error:0.24041\n",
      "[161]\tvalidation_0-error:0.24041\n",
      "[162]\tvalidation_0-error:0.24050\n",
      "[163]\tvalidation_0-error:0.24054\n",
      "[164]\tvalidation_0-error:0.24056\n",
      "[165]\tvalidation_0-error:0.24045\n",
      "[166]\tvalidation_0-error:0.24052\n",
      "[167]\tvalidation_0-error:0.24055\n",
      "[168]\tvalidation_0-error:0.24049\n",
      "[169]\tvalidation_0-error:0.24047\n",
      "[170]\tvalidation_0-error:0.24034\n",
      "[171]\tvalidation_0-error:0.24027\n",
      "[172]\tvalidation_0-error:0.24042\n",
      "[173]\tvalidation_0-error:0.24035\n",
      "[174]\tvalidation_0-error:0.24041\n",
      "[175]\tvalidation_0-error:0.24039\n",
      "[176]\tvalidation_0-error:0.24042\n",
      "[177]\tvalidation_0-error:0.24057\n",
      "[178]\tvalidation_0-error:0.24054\n",
      "[179]\tvalidation_0-error:0.24052\n",
      "[180]\tvalidation_0-error:0.24052\n",
      "[181]\tvalidation_0-error:0.24048\n",
      "[182]\tvalidation_0-error:0.24040\n",
      "[183]\tvalidation_0-error:0.24051\n",
      "[184]\tvalidation_0-error:0.24053\n",
      "[185]\tvalidation_0-error:0.24054\n",
      "[186]\tvalidation_0-error:0.24059\n",
      "[187]\tvalidation_0-error:0.24058\n",
      "[188]\tvalidation_0-error:0.24058\n",
      "[189]\tvalidation_0-error:0.24059\n",
      "[190]\tvalidation_0-error:0.24056\n",
      "[191]\tvalidation_0-error:0.24060\n",
      "[192]\tvalidation_0-error:0.24067\n",
      "[193]\tvalidation_0-error:0.24074\n",
      "[194]\tvalidation_0-error:0.24069\n",
      "[195]\tvalidation_0-error:0.24074\n",
      "[196]\tvalidation_0-error:0.24072\n",
      "[197]\tvalidation_0-error:0.24075\n",
      "[198]\tvalidation_0-error:0.24074\n",
      "[199]\tvalidation_0-error:0.24062\n",
      "[200]\tvalidation_0-error:0.24062\n",
      "[201]\tvalidation_0-error:0.24058\n",
      "[202]\tvalidation_0-error:0.24060\n",
      "[203]\tvalidation_0-error:0.24063\n",
      "[204]\tvalidation_0-error:0.24062\n",
      "[205]\tvalidation_0-error:0.24063\n",
      "[206]\tvalidation_0-error:0.24069\n",
      "[207]\tvalidation_0-error:0.24066\n",
      "[208]\tvalidation_0-error:0.24063\n",
      "[209]\tvalidation_0-error:0.24049\n",
      "[210]\tvalidation_0-error:0.24046\n",
      "[211]\tvalidation_0-error:0.24059\n",
      "[212]\tvalidation_0-error:0.24046\n",
      "[213]\tvalidation_0-error:0.24039\n",
      "[214]\tvalidation_0-error:0.24039\n",
      "[215]\tvalidation_0-error:0.24041\n",
      "[216]\tvalidation_0-error:0.24046\n",
      "[217]\tvalidation_0-error:0.24036\n",
      "[218]\tvalidation_0-error:0.24035\n",
      "[219]\tvalidation_0-error:0.24039\n",
      "[220]\tvalidation_0-error:0.24029\n",
      "[221]\tvalidation_0-error:0.24033\n",
      "[222]\tvalidation_0-error:0.24035\n",
      "[223]\tvalidation_0-error:0.24038\n",
      "[224]\tvalidation_0-error:0.24043\n",
      "[225]\tvalidation_0-error:0.24045\n",
      "[226]\tvalidation_0-error:0.24030\n",
      "[227]\tvalidation_0-error:0.24035\n",
      "[228]\tvalidation_0-error:0.24045\n",
      "[229]\tvalidation_0-error:0.24036\n",
      "[230]\tvalidation_0-error:0.24042\n",
      "[231]\tvalidation_0-error:0.24038\n",
      "[232]\tvalidation_0-error:0.24033\n",
      "[233]\tvalidation_0-error:0.24022\n",
      "[234]\tvalidation_0-error:0.24018\n",
      "[235]\tvalidation_0-error:0.24022\n",
      "[236]\tvalidation_0-error:0.24022\n",
      "[237]\tvalidation_0-error:0.24018\n",
      "[238]\tvalidation_0-error:0.24016\n",
      "[239]\tvalidation_0-error:0.24021\n",
      "[240]\tvalidation_0-error:0.24016\n",
      "[241]\tvalidation_0-error:0.24019\n",
      "[242]\tvalidation_0-error:0.24018\n",
      "[243]\tvalidation_0-error:0.24016\n",
      "[244]\tvalidation_0-error:0.24011\n",
      "[245]\tvalidation_0-error:0.24013\n",
      "[246]\tvalidation_0-error:0.24028\n",
      "[247]\tvalidation_0-error:0.24024\n",
      "[248]\tvalidation_0-error:0.24028\n",
      "[249]\tvalidation_0-error:0.24020\n",
      "[250]\tvalidation_0-error:0.24012\n",
      "[251]\tvalidation_0-error:0.24024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[252]\tvalidation_0-error:0.24026\n",
      "[253]\tvalidation_0-error:0.24018\n",
      "[254]\tvalidation_0-error:0.24024\n",
      "[255]\tvalidation_0-error:0.24019\n",
      "[256]\tvalidation_0-error:0.24030\n",
      "[257]\tvalidation_0-error:0.24032\n",
      "[258]\tvalidation_0-error:0.24034\n",
      "[259]\tvalidation_0-error:0.24024\n",
      "[260]\tvalidation_0-error:0.24033\n",
      "[261]\tvalidation_0-error:0.24034\n",
      "[262]\tvalidation_0-error:0.24029\n",
      "[263]\tvalidation_0-error:0.24029\n",
      "[264]\tvalidation_0-error:0.24021\n",
      "[265]\tvalidation_0-error:0.24023\n",
      "[266]\tvalidation_0-error:0.24019\n",
      "[267]\tvalidation_0-error:0.24021\n",
      "[268]\tvalidation_0-error:0.24007\n",
      "[269]\tvalidation_0-error:0.24011\n",
      "[270]\tvalidation_0-error:0.24020\n",
      "[271]\tvalidation_0-error:0.24019\n",
      "[272]\tvalidation_0-error:0.24016\n",
      "[273]\tvalidation_0-error:0.24013\n",
      "[274]\tvalidation_0-error:0.24016\n",
      "[275]\tvalidation_0-error:0.24016\n",
      "[276]\tvalidation_0-error:0.24004\n",
      "[277]\tvalidation_0-error:0.24003\n",
      "[278]\tvalidation_0-error:0.24002\n",
      "[279]\tvalidation_0-error:0.24001\n",
      "[280]\tvalidation_0-error:0.23998\n",
      "[281]\tvalidation_0-error:0.24004\n",
      "[282]\tvalidation_0-error:0.23996\n",
      "[283]\tvalidation_0-error:0.23997\n",
      "[284]\tvalidation_0-error:0.24000\n",
      "[285]\tvalidation_0-error:0.24003\n",
      "[286]\tvalidation_0-error:0.24000\n",
      "[287]\tvalidation_0-error:0.23995\n",
      "[288]\tvalidation_0-error:0.24004\n",
      "[289]\tvalidation_0-error:0.23999\n",
      "[290]\tvalidation_0-error:0.23996\n",
      "[291]\tvalidation_0-error:0.23999\n",
      "[292]\tvalidation_0-error:0.24003\n",
      "[293]\tvalidation_0-error:0.24010\n",
      "[294]\tvalidation_0-error:0.23995\n",
      "[295]\tvalidation_0-error:0.23997\n",
      "[296]\tvalidation_0-error:0.23994\n",
      "[297]\tvalidation_0-error:0.23994\n",
      "[298]\tvalidation_0-error:0.23992\n",
      "[299]\tvalidation_0-error:0.24001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 75.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 94.75247999999999\n"
     ]
    }
   ],
   "source": [
    "# changing n_estimators only\n",
    "# Inference 1: the more the value, the better the accuracy\n",
    "    # (need to plot it with matplotlib later for more details and will include in doc.)... \n",
    "    # takes equal time (around 3s for every step) and\n",
    "    # time taken increases linearly with every step numbers (n_estimators).\n",
    "# Inference 2: For every value of n_estimators, (i.e. for each iteration of the for loop)\n",
    "    # the value of accuracy at the \"n\"th step remains constant\n",
    "    # so had there been a way to save the progress it would have been helpful\n",
    "\n",
    "model = XGBClassifier(tree_method='gpu_hist',\n",
    "                      booster = 'gbtree',\n",
    "                      max_depth = 14,\n",
    "                      n_estimators = 300,\n",
    "                      learning_rate = 0.4\n",
    "                     ) # booster = gbtree, dart\n",
    "\n",
    "eval_set = [(x_test_alpha, y_test_alpha)]\n",
    "\n",
    "a = model.fit(x_train_alpha,\n",
    "              y_train_alpha,\n",
    "              eval_metric=\"error\",\n",
    "              eval_set=eval_set,\n",
    "              verbose=True)\n",
    "    \n",
    "y_test_alpha_pred = model.predict(x_test_alpha,ntree_limit=model.best_ntree_limit)\n",
    "accuracy_test = accuracy_score(y_test_alpha, y_test_alpha_pred)\n",
    "print(\"The testing accuracy\", accuracy_test*100)\n",
    "    \n",
    "y_train_alpha_pred=model.predict(x_train_alpha,ntree_limit=model.best_ntree_limit)\n",
    "accuracy_train = accuracy_score(y_train_alpha, y_train_alpha_pred)\n",
    "print(\"The training accuracy\", accuracy_train*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01c9afd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{50: {'test': 0.755787, 'train': 0.8180156},\n",
      " 60: {'test': 0.757704, 'train': 0.8299261},\n",
      " 70: {'test': 0.758303, 'train': 0.8371179},\n",
      " 80: {'test': 0.758716, 'train': 0.8445728},\n",
      " 90: {'test': 0.758777, 'train': 0.8515553},\n",
      " 100: {'test': 0.758995, 'train': 0.858091},\n",
      " 110: {'test': 0.759138, 'train': 0.8657}}\n"
     ]
    }
   ],
   "source": [
    "pprint(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = {}\n",
    "for i in range(15, 20):\n",
    "    print(f\"max depth = {i}\")\n",
    "    t0 = time()\n",
    "    model = XGBClassifier(tree_method='gpu_hist',\n",
    "                      booster = 'gbtree',\n",
    "                      max_depth = i,\n",
    "                      n_estimators = 50,\n",
    "                      learning_rate = 0.4\n",
    "                     ) # booster = gbtree, dart\n",
    "\n",
    "    eval_set = [(x_test_alpha, y_test_alpha)]\n",
    "\n",
    "    a = model.fit(x_train_alpha,\n",
    "              y_train_alpha,\n",
    "              eval_metric=\"error\",\n",
    "              eval_set=eval_set,\n",
    "              verbose=True)\n",
    "    \n",
    "    y_test_alpha_pred = model.predict(x_test_alpha,ntree_limit=model.best_ntree_limit)\n",
    "    accuracy_test = accuracy_score(y_test_alpha, y_test_alpha_pred)\n",
    "    print(\"The testing accuracy\", accuracy_test*100)\n",
    "    \n",
    "    y_train_alpha_pred=model.predict(x_train_alpha,ntree_limit=model.best_ntree_limit)\n",
    "    accuracy_train = accuracy_score(y_train_alpha, y_train_alpha_pred)\n",
    "    print(\"The training accuracy\", accuracy_train*100)\n",
    "    \n",
    "    taken = time()-t0\n",
    "    d2[i] = {\"test\": accuracy_test, \"train\": accuracy_train, \"taken\": taken}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95b6a4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: {'taken': 36.36368489265442, 'test': 0.751825, 'train': 0.7608359},\n",
      " 11: {'taken': 36.673232078552246, 'test': 0.753068, 'train': 0.7686388},\n",
      " 12: {'taken': 46.62508583068848, 'test': 0.754978, 'train': 0.7810104},\n",
      " 13: {'taken': 64.10936331748962, 'test': 0.756251, 'train': 0.7967713},\n",
      " 14: {'taken': 90.26022219657898, 'test': 0.756528, 'train': 0.8176108}}\n"
     ]
    }
   ],
   "source": [
    "pprint(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69a63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c850d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6df7a29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31390\n",
      "[2]\tvalidation_0-error:0.30712\n",
      "[3]\tvalidation_0-error:0.29759\n",
      "[4]\tvalidation_0-error:0.29458\n",
      "[5]\tvalidation_0-error:0.29171\n",
      "[6]\tvalidation_0-error:0.28900\n",
      "[7]\tvalidation_0-error:0.28714\n",
      "[8]\tvalidation_0-error:0.28581\n",
      "[9]\tvalidation_0-error:0.28434\n",
      "The testing accuracy 71.5659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.53828\n",
      "7.126391410827637\n",
      "learning rate = 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31449\n",
      "[2]\tvalidation_0-error:0.30796\n",
      "[3]\tvalidation_0-error:0.30078\n",
      "[4]\tvalidation_0-error:0.29482\n",
      "[5]\tvalidation_0-error:0.29163\n",
      "[6]\tvalidation_0-error:0.29044\n",
      "[7]\tvalidation_0-error:0.28854\n",
      "[8]\tvalidation_0-error:0.28741\n",
      "[9]\tvalidation_0-error:0.28598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.4019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.43836\n",
      "7.015458822250366\n",
      "learning rate = 0.8200000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31747\n",
      "[2]\tvalidation_0-error:0.30724\n",
      "[3]\tvalidation_0-error:0.30274\n",
      "[4]\tvalidation_0-error:0.29733\n",
      "[5]\tvalidation_0-error:0.29446\n",
      "[6]\tvalidation_0-error:0.29224\n",
      "[7]\tvalidation_0-error:0.29022\n",
      "[8]\tvalidation_0-error:0.28845\n",
      "[9]\tvalidation_0-error:0.28607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.3934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.38923\n",
      "7.672198534011841\n",
      "learning rate = 0.8300000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31745\n",
      "[2]\tvalidation_0-error:0.30625\n",
      "[3]\tvalidation_0-error:0.30152\n",
      "[4]\tvalidation_0-error:0.29757\n",
      "[5]\tvalidation_0-error:0.29440\n",
      "[6]\tvalidation_0-error:0.29097\n",
      "[7]\tvalidation_0-error:0.28861\n",
      "[8]\tvalidation_0-error:0.28732\n",
      "[9]\tvalidation_0-error:0.28625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.3755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.42817000000001\n",
      "8.000215291976929\n",
      "learning rate = 0.8400000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31745\n",
      "[2]\tvalidation_0-error:0.30591\n",
      "[3]\tvalidation_0-error:0.30147\n",
      "[4]\tvalidation_0-error:0.29761\n",
      "[5]\tvalidation_0-error:0.29438\n",
      "[6]\tvalidation_0-error:0.29070\n",
      "[7]\tvalidation_0-error:0.28947\n",
      "[8]\tvalidation_0-error:0.28767\n",
      "[9]\tvalidation_0-error:0.28695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.3052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.32776\n",
      "8.109199047088623\n",
      "learning rate = 0.8500000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31805\n",
      "[2]\tvalidation_0-error:0.30713\n",
      "[3]\tvalidation_0-error:0.30158\n",
      "[4]\tvalidation_0-error:0.29732\n",
      "[5]\tvalidation_0-error:0.29404\n",
      "[6]\tvalidation_0-error:0.29021\n",
      "[7]\tvalidation_0-error:0.28895\n",
      "[8]\tvalidation_0-error:0.28784\n",
      "[9]\tvalidation_0-error:0.28712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.2883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.31979000000001\n",
      "7.593679904937744\n",
      "learning rate = 0.8600000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31809\n",
      "[2]\tvalidation_0-error:0.30677\n",
      "[3]\tvalidation_0-error:0.29986\n",
      "[4]\tvalidation_0-error:0.29667\n",
      "[5]\tvalidation_0-error:0.29349\n",
      "[6]\tvalidation_0-error:0.29195\n",
      "[7]\tvalidation_0-error:0.29004\n",
      "[8]\tvalidation_0-error:0.28780\n",
      "[9]\tvalidation_0-error:0.28677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.32270000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.35924\n",
      "7.062563419342041\n",
      "learning rate = 0.8700000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31810\n",
      "[2]\tvalidation_0-error:0.30637\n",
      "[3]\tvalidation_0-error:0.30123\n",
      "[4]\tvalidation_0-error:0.29569\n",
      "[5]\tvalidation_0-error:0.29305\n",
      "[6]\tvalidation_0-error:0.29152\n",
      "[7]\tvalidation_0-error:0.28951\n",
      "[8]\tvalidation_0-error:0.28774\n",
      "[9]\tvalidation_0-error:0.28557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.4429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.45026\n",
      "7.814123630523682\n",
      "learning rate = 0.8800000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31696\n",
      "[2]\tvalidation_0-error:0.30694\n",
      "[3]\tvalidation_0-error:0.30044\n",
      "[4]\tvalidation_0-error:0.29711\n",
      "[5]\tvalidation_0-error:0.29307\n",
      "[6]\tvalidation_0-error:0.29093\n",
      "[7]\tvalidation_0-error:0.28903\n",
      "[8]\tvalidation_0-error:0.28650\n",
      "[9]\tvalidation_0-error:0.28507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.52418\n",
      "7.796854019165039\n",
      "learning rate = 0.8900000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31671\n",
      "[2]\tvalidation_0-error:0.30611\n",
      "[3]\tvalidation_0-error:0.30095\n",
      "[4]\tvalidation_0-error:0.29749\n",
      "[5]\tvalidation_0-error:0.29304\n",
      "[6]\tvalidation_0-error:0.29155\n",
      "[7]\tvalidation_0-error:0.28980\n",
      "[8]\tvalidation_0-error:0.28825\n",
      "[9]\tvalidation_0-error:0.28661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.3387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.35275\n",
      "7.093327760696411\n",
      "learning rate = 0.9000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31644\n",
      "[2]\tvalidation_0-error:0.30640\n",
      "[3]\tvalidation_0-error:0.30172\n",
      "[4]\tvalidation_0-error:0.29694\n",
      "[5]\tvalidation_0-error:0.29296\n",
      "[6]\tvalidation_0-error:0.29045\n",
      "[7]\tvalidation_0-error:0.28951\n",
      "[8]\tvalidation_0-error:0.28694\n",
      "[9]\tvalidation_0-error:0.28433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.56660000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.552\n",
      "8.281227111816406\n",
      "learning rate = 0.9100000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31584\n",
      "[2]\tvalidation_0-error:0.30642\n",
      "[3]\tvalidation_0-error:0.30171\n",
      "[4]\tvalidation_0-error:0.29704\n",
      "[5]\tvalidation_0-error:0.29377\n",
      "[6]\tvalidation_0-error:0.29211\n",
      "[7]\tvalidation_0-error:0.29090\n",
      "[8]\tvalidation_0-error:0.29022\n",
      "[9]\tvalidation_0-error:0.28734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.28972999999999\n",
      "6.906344413757324\n",
      "learning rate = 0.9200000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31588\n",
      "[2]\tvalidation_0-error:0.30674\n",
      "[3]\tvalidation_0-error:0.30184\n",
      "[4]\tvalidation_0-error:0.29727\n",
      "[5]\tvalidation_0-error:0.29384\n",
      "[6]\tvalidation_0-error:0.29254\n",
      "[7]\tvalidation_0-error:0.29169\n",
      "[8]\tvalidation_0-error:0.28853\n",
      "[9]\tvalidation_0-error:0.28683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.3171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.36462\n",
      "6.999918699264526\n",
      "learning rate = 0.9300000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31584\n",
      "[2]\tvalidation_0-error:0.30670\n",
      "[3]\tvalidation_0-error:0.30183\n",
      "[4]\tvalidation_0-error:0.29736\n",
      "[5]\tvalidation_0-error:0.29397\n",
      "[6]\tvalidation_0-error:0.29273\n",
      "[7]\tvalidation_0-error:0.29190\n",
      "[8]\tvalidation_0-error:0.28862\n",
      "[9]\tvalidation_0-error:0.28703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.37044\n",
      "7.046724081039429\n",
      "learning rate = 0.9400000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.33589\n",
      "[1]\tvalidation_0-error:0.31562\n",
      "[2]\tvalidation_0-error:0.30691\n",
      "[3]\tvalidation_0-error:0.30058\n",
      "[4]\tvalidation_0-error:0.29748\n",
      "[5]\tvalidation_0-error:0.29444\n",
      "[6]\tvalidation_0-error:0.29268\n",
      "[7]\tvalidation_0-error:0.28964\n",
      "[8]\tvalidation_0-error:0.28760\n",
      "[9]\tvalidation_0-error:0.28702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 71.2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 71.33382\n",
      "7.828173875808716\n"
     ]
    }
   ],
   "source": [
    "i=0.\n",
    "for i in np.arange(0.8, 0.95, 0.01):\n",
    "    print(f\"learning rate = {i}\")\n",
    "    model = XGBClassifier(tree_method='gpu_hist',\n",
    "                          booster = 'gbtree',\n",
    "                          max_depth = 5, # 19\n",
    "                          n_estimators = 10, # 50\n",
    "                          learning_rate = i\n",
    "                         ) # booster = gbtree, dart\n",
    "\n",
    "    eval_set = [(x_test_alpha, y_test_alpha)]\n",
    "\n",
    "    t0 = time()\n",
    "    a = model.fit(x_train_alpha,\n",
    "              y_train_alpha,\n",
    "              eval_metric=\"error\",\n",
    "              eval_set=eval_set,\n",
    "              verbose=True)\n",
    "    taken = time()-t0\n",
    "\n",
    "    y_test_alpha_pred = model.predict(x_test_alpha,ntree_limit=model.best_ntree_limit)\n",
    "    accuracy_test = accuracy_score(y_test_alpha, y_test_alpha_pred)\n",
    "    print(\"The testing accuracy\", accuracy_test*100)\n",
    "\n",
    "    y_train_alpha_pred=model.predict(x_train_alpha,ntree_limit=model.best_ntree_limit)\n",
    "    accuracy_train = accuracy_score(y_train_alpha, y_train_alpha_pred)\n",
    "    print(\"The training accuracy\", accuracy_train*100)\n",
    "\n",
    "\n",
    "    print(taken)\n",
    "    ll2[i] = {\"test\": accuracy_test, \"train\": accuracy_train, \"taken\": taken}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfeb76a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.7: {'taken': 7.217034101486206, 'test': 0.714913, 'train': 0.7149148},\n",
      " 0.8: {'taken': 7.126391410827637, 'test': 0.715659, 'train': 0.7153828},\n",
      " 0.81: {'taken': 7.015458822250366, 'test': 0.714019, 'train': 0.7143836},\n",
      " 0.8200000000000001: {'taken': 7.672198534011841,\n",
      "                      'test': 0.713934,\n",
      "                      'train': 0.7138923},\n",
      " 0.8300000000000001: {'taken': 8.000215291976929,\n",
      "                      'test': 0.713755,\n",
      "                      'train': 0.7142817},\n",
      " 0.8400000000000001: {'taken': 8.109199047088623,\n",
      "                      'test': 0.713052,\n",
      "                      'train': 0.7132776},\n",
      " 0.8500000000000001: {'taken': 7.593679904937744,\n",
      "                      'test': 0.712883,\n",
      "                      'train': 0.7131979},\n",
      " 0.8600000000000001: {'taken': 7.062563419342041,\n",
      "                      'test': 0.713227,\n",
      "                      'train': 0.7135924},\n",
      " 0.8700000000000001: {'taken': 7.814123630523682,\n",
      "                      'test': 0.714429,\n",
      "                      'train': 0.7145026},\n",
      " 0.8800000000000001: {'taken': 7.796854019165039,\n",
      "                      'test': 0.714934,\n",
      "                      'train': 0.7152418},\n",
      " 0.8900000000000001: {'taken': 7.093327760696411,\n",
      "                      'test': 0.713387,\n",
      "                      'train': 0.7135275},\n",
      " 0.9: {'taken': 7.915523529052734, 'test': 0.715666, 'train': 0.71552},\n",
      " 0.9000000000000001: {'taken': 8.281227111816406,\n",
      "                      'test': 0.715666,\n",
      "                      'train': 0.71552},\n",
      " 0.9100000000000001: {'taken': 6.906344413757324,\n",
      "                      'test': 0.712658,\n",
      "                      'train': 0.7128973},\n",
      " 0.9200000000000002: {'taken': 6.999918699264526,\n",
      "                      'test': 0.713171,\n",
      "                      'train': 0.7136462},\n",
      " 0.9300000000000002: {'taken': 7.046724081039429,\n",
      "                      'test': 0.712971,\n",
      "                      'train': 0.7137044},\n",
      " 0.9400000000000002: {'taken': 7.828173875808716,\n",
      "                      'test': 0.712978,\n",
      "                      'train': 0.7133382},\n",
      " 0.95: {'taken': 7.809328556060791, 'test': 0.713066, 'train': 0.7129311}}\n"
     ]
    }
   ],
   "source": [
    "pprint(ll2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a47d7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.01: {'taken': 7.312809228897095, 'test': 0.667626, 'train': 0.6679434},\n",
      " 0.02: {'taken': 7.182486534118652, 'test': 0.670771, 'train': 0.6709408},\n",
      " 0.05: {'taken': 7.081484317779541, 'test': 0.678753, 'train': 0.6787962},\n",
      " 0.1: {'taken': 7.2065393924713135, 'test': 0.688295, 'train': 0.6883355},\n",
      " 0.2: {'taken': 7.124792814254761, 'test': 0.703557, 'train': 0.7035396},\n",
      " 0.5: {'taken': 7.069786548614502, 'test': 0.713414, 'train': 0.7128506},\n",
      " 0.9: {'taken': 7.903645277023315, 'test': 0.715666, 'train': 0.71552},\n",
      " 1.1: {'taken': 7.100404262542725, 'test': 0.711696, 'train': 0.7118216},\n",
      " 1.5: {'taken': 7.040217161178589, 'test': 0.704638, 'train': 0.7049334}}\n"
     ]
    }
   ],
   "source": [
    "pprint(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec82b4a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.27986\n",
      "[1]\tvalidation_0-error:0.27496\n",
      "[2]\tvalidation_0-error:0.27160\n",
      "[3]\tvalidation_0-error:0.26779\n",
      "[4]\tvalidation_0-error:0.26581\n",
      "[5]\tvalidation_0-error:0.26376\n",
      "[6]\tvalidation_0-error:0.26207\n",
      "[7]\tvalidation_0-error:0.26081\n",
      "[8]\tvalidation_0-error:0.25968\n",
      "[9]\tvalidation_0-error:0.25860\n",
      "[10]\tvalidation_0-error:0.25753\n",
      "[11]\tvalidation_0-error:0.25685\n",
      "[12]\tvalidation_0-error:0.25599\n",
      "[13]\tvalidation_0-error:0.25534\n",
      "[14]\tvalidation_0-error:0.25492\n",
      "[15]\tvalidation_0-error:0.25389\n",
      "[16]\tvalidation_0-error:0.25356\n",
      "[17]\tvalidation_0-error:0.25305\n",
      "[18]\tvalidation_0-error:0.25240\n",
      "[19]\tvalidation_0-error:0.25165\n",
      "[20]\tvalidation_0-error:0.25145\n",
      "[21]\tvalidation_0-error:0.25081\n",
      "[22]\tvalidation_0-error:0.25015\n",
      "[23]\tvalidation_0-error:0.24951\n",
      "[24]\tvalidation_0-error:0.24912\n",
      "[25]\tvalidation_0-error:0.24882\n",
      "[26]\tvalidation_0-error:0.24876\n",
      "[27]\tvalidation_0-error:0.24825\n",
      "[28]\tvalidation_0-error:0.24787\n",
      "[29]\tvalidation_0-error:0.24761\n",
      "[30]\tvalidation_0-error:0.24744\n",
      "[31]\tvalidation_0-error:0.24714\n",
      "[32]\tvalidation_0-error:0.24709\n",
      "[33]\tvalidation_0-error:0.24671\n",
      "[34]\tvalidation_0-error:0.24637\n",
      "[35]\tvalidation_0-error:0.24607\n",
      "[36]\tvalidation_0-error:0.24580\n",
      "[37]\tvalidation_0-error:0.24571\n",
      "[38]\tvalidation_0-error:0.24540\n",
      "[39]\tvalidation_0-error:0.24521\n",
      "[40]\tvalidation_0-error:0.24503\n",
      "[41]\tvalidation_0-error:0.24483\n",
      "[42]\tvalidation_0-error:0.24454\n",
      "[43]\tvalidation_0-error:0.24433\n",
      "[44]\tvalidation_0-error:0.24406\n",
      "[45]\tvalidation_0-error:0.24407\n",
      "[46]\tvalidation_0-error:0.24404\n",
      "[47]\tvalidation_0-error:0.24399\n",
      "[48]\tvalidation_0-error:0.24362\n",
      "[49]\tvalidation_0-error:0.24337\n",
      "[50]\tvalidation_0-error:0.24323\n",
      "[51]\tvalidation_0-error:0.24312\n",
      "[52]\tvalidation_0-error:0.24305\n",
      "[53]\tvalidation_0-error:0.24289\n",
      "[54]\tvalidation_0-error:0.24274\n",
      "[55]\tvalidation_0-error:0.24269\n",
      "[56]\tvalidation_0-error:0.24258\n",
      "[57]\tvalidation_0-error:0.24239\n",
      "[58]\tvalidation_0-error:0.24217\n",
      "[59]\tvalidation_0-error:0.24151\n",
      "[60]\tvalidation_0-error:0.24144\n",
      "[61]\tvalidation_0-error:0.24123\n",
      "[62]\tvalidation_0-error:0.24127\n",
      "[63]\tvalidation_0-error:0.24112\n",
      "[64]\tvalidation_0-error:0.24101\n",
      "[65]\tvalidation_0-error:0.24077\n",
      "[66]\tvalidation_0-error:0.24057\n",
      "[67]\tvalidation_0-error:0.24051\n",
      "[68]\tvalidation_0-error:0.24028\n",
      "[69]\tvalidation_0-error:0.24002\n",
      "[70]\tvalidation_0-error:0.23994\n",
      "[71]\tvalidation_0-error:0.23969\n",
      "[72]\tvalidation_0-error:0.23943\n",
      "[73]\tvalidation_0-error:0.23922\n",
      "[74]\tvalidation_0-error:0.23906\n",
      "[75]\tvalidation_0-error:0.23902\n",
      "[76]\tvalidation_0-error:0.23887\n",
      "[77]\tvalidation_0-error:0.23890\n",
      "[78]\tvalidation_0-error:0.23879\n",
      "[79]\tvalidation_0-error:0.23870\n",
      "[80]\tvalidation_0-error:0.23861\n",
      "[81]\tvalidation_0-error:0.23850\n",
      "[82]\tvalidation_0-error:0.23847\n",
      "[83]\tvalidation_0-error:0.23842\n",
      "[84]\tvalidation_0-error:0.23833\n",
      "[85]\tvalidation_0-error:0.23826\n",
      "[86]\tvalidation_0-error:0.23822\n",
      "[87]\tvalidation_0-error:0.23799\n",
      "[88]\tvalidation_0-error:0.23785\n",
      "[89]\tvalidation_0-error:0.23776\n",
      "[90]\tvalidation_0-error:0.23764\n",
      "[91]\tvalidation_0-error:0.23754\n",
      "[92]\tvalidation_0-error:0.23746\n",
      "[93]\tvalidation_0-error:0.23739\n",
      "[94]\tvalidation_0-error:0.23736\n",
      "[95]\tvalidation_0-error:0.23734\n",
      "[96]\tvalidation_0-error:0.23718\n",
      "[97]\tvalidation_0-error:0.23715\n",
      "[98]\tvalidation_0-error:0.23709\n",
      "[99]\tvalidation_0-error:0.23708\n",
      "[100]\tvalidation_0-error:0.23705\n",
      "[101]\tvalidation_0-error:0.23702\n",
      "[102]\tvalidation_0-error:0.23699\n",
      "[103]\tvalidation_0-error:0.23691\n",
      "[104]\tvalidation_0-error:0.23684\n",
      "[105]\tvalidation_0-error:0.23680\n",
      "[106]\tvalidation_0-error:0.23677\n",
      "[107]\tvalidation_0-error:0.23662\n",
      "[108]\tvalidation_0-error:0.23658\n",
      "[109]\tvalidation_0-error:0.23641\n",
      "[110]\tvalidation_0-error:0.23629\n",
      "[111]\tvalidation_0-error:0.23617\n",
      "[112]\tvalidation_0-error:0.23608\n",
      "[113]\tvalidation_0-error:0.23608\n",
      "[114]\tvalidation_0-error:0.23605\n",
      "[115]\tvalidation_0-error:0.23592\n",
      "[116]\tvalidation_0-error:0.23593\n",
      "[117]\tvalidation_0-error:0.23596\n",
      "[118]\tvalidation_0-error:0.23590\n",
      "[119]\tvalidation_0-error:0.23581\n",
      "[120]\tvalidation_0-error:0.23577\n",
      "[121]\tvalidation_0-error:0.23576\n",
      "[122]\tvalidation_0-error:0.23576\n",
      "[123]\tvalidation_0-error:0.23568\n",
      "[124]\tvalidation_0-error:0.23572\n",
      "[125]\tvalidation_0-error:0.23566\n",
      "[126]\tvalidation_0-error:0.23550\n",
      "[127]\tvalidation_0-error:0.23542\n",
      "[128]\tvalidation_0-error:0.23544\n",
      "[129]\tvalidation_0-error:0.23531\n",
      "[130]\tvalidation_0-error:0.23523\n",
      "[131]\tvalidation_0-error:0.23517\n",
      "[132]\tvalidation_0-error:0.23507\n",
      "[133]\tvalidation_0-error:0.23511\n",
      "[134]\tvalidation_0-error:0.23506\n",
      "[135]\tvalidation_0-error:0.23498\n",
      "[136]\tvalidation_0-error:0.23502\n",
      "[137]\tvalidation_0-error:0.23500\n",
      "[138]\tvalidation_0-error:0.23498\n",
      "[139]\tvalidation_0-error:0.23470\n",
      "[140]\tvalidation_0-error:0.23475\n",
      "[141]\tvalidation_0-error:0.23467\n",
      "[142]\tvalidation_0-error:0.23469\n",
      "[143]\tvalidation_0-error:0.23469\n",
      "[144]\tvalidation_0-error:0.23464\n",
      "[145]\tvalidation_0-error:0.23456\n",
      "[146]\tvalidation_0-error:0.23459\n",
      "[147]\tvalidation_0-error:0.23440\n",
      "[148]\tvalidation_0-error:0.23436\n",
      "[149]\tvalidation_0-error:0.23429\n",
      "[150]\tvalidation_0-error:0.23417\n",
      "[151]\tvalidation_0-error:0.23428\n",
      "[152]\tvalidation_0-error:0.23431\n",
      "[153]\tvalidation_0-error:0.23431\n",
      "[154]\tvalidation_0-error:0.23417\n",
      "[155]\tvalidation_0-error:0.23420\n",
      "[156]\tvalidation_0-error:0.23409\n",
      "[157]\tvalidation_0-error:0.23405\n",
      "[158]\tvalidation_0-error:0.23409\n",
      "[159]\tvalidation_0-error:0.23397\n",
      "[160]\tvalidation_0-error:0.23405\n",
      "[161]\tvalidation_0-error:0.23406\n",
      "[162]\tvalidation_0-error:0.23393\n",
      "[163]\tvalidation_0-error:0.23395\n",
      "[164]\tvalidation_0-error:0.23390\n",
      "[165]\tvalidation_0-error:0.23384\n",
      "[166]\tvalidation_0-error:0.23397\n",
      "[167]\tvalidation_0-error:0.23394\n",
      "[168]\tvalidation_0-error:0.23383\n",
      "[169]\tvalidation_0-error:0.23388\n",
      "[170]\tvalidation_0-error:0.23384\n",
      "[171]\tvalidation_0-error:0.23377\n",
      "[172]\tvalidation_0-error:0.23375\n",
      "[173]\tvalidation_0-error:0.23378\n",
      "[174]\tvalidation_0-error:0.23382\n",
      "[175]\tvalidation_0-error:0.23372\n",
      "[176]\tvalidation_0-error:0.23368\n",
      "[177]\tvalidation_0-error:0.23367\n",
      "[178]\tvalidation_0-error:0.23356\n",
      "[179]\tvalidation_0-error:0.23359\n",
      "[180]\tvalidation_0-error:0.23348\n",
      "[181]\tvalidation_0-error:0.23356\n",
      "[182]\tvalidation_0-error:0.23338\n",
      "[183]\tvalidation_0-error:0.23337\n",
      "[184]\tvalidation_0-error:0.23342\n",
      "[185]\tvalidation_0-error:0.23342\n",
      "[186]\tvalidation_0-error:0.23327\n",
      "[187]\tvalidation_0-error:0.23320\n",
      "[188]\tvalidation_0-error:0.23320\n",
      "[189]\tvalidation_0-error:0.23322\n",
      "[190]\tvalidation_0-error:0.23313\n",
      "[191]\tvalidation_0-error:0.23310\n",
      "[192]\tvalidation_0-error:0.23302\n",
      "[193]\tvalidation_0-error:0.23302\n",
      "[194]\tvalidation_0-error:0.23302\n",
      "[195]\tvalidation_0-error:0.23303\n",
      "[196]\tvalidation_0-error:0.23297\n",
      "[197]\tvalidation_0-error:0.23296\n",
      "[198]\tvalidation_0-error:0.23293\n",
      "[199]\tvalidation_0-error:0.23296\n",
      "[200]\tvalidation_0-error:0.23292\n",
      "[201]\tvalidation_0-error:0.23284\n",
      "[202]\tvalidation_0-error:0.23281\n",
      "[203]\tvalidation_0-error:0.23263\n",
      "[204]\tvalidation_0-error:0.23263\n",
      "[205]\tvalidation_0-error:0.23261\n",
      "[206]\tvalidation_0-error:0.23267\n",
      "[207]\tvalidation_0-error:0.23267\n",
      "[208]\tvalidation_0-error:0.23268\n",
      "[209]\tvalidation_0-error:0.23262\n",
      "[210]\tvalidation_0-error:0.23260\n",
      "[211]\tvalidation_0-error:0.23254\n",
      "[212]\tvalidation_0-error:0.23258\n",
      "[213]\tvalidation_0-error:0.23259\n",
      "[214]\tvalidation_0-error:0.23259\n",
      "[215]\tvalidation_0-error:0.23254\n",
      "[216]\tvalidation_0-error:0.23240\n",
      "[217]\tvalidation_0-error:0.23238\n",
      "[218]\tvalidation_0-error:0.23233\n",
      "[219]\tvalidation_0-error:0.23231\n",
      "[220]\tvalidation_0-error:0.23223\n",
      "[221]\tvalidation_0-error:0.23225\n",
      "[222]\tvalidation_0-error:0.23225\n",
      "[223]\tvalidation_0-error:0.23226\n",
      "[224]\tvalidation_0-error:0.23231\n",
      "[225]\tvalidation_0-error:0.23221\n",
      "[226]\tvalidation_0-error:0.23226\n",
      "[227]\tvalidation_0-error:0.23234\n",
      "[228]\tvalidation_0-error:0.23227\n",
      "[229]\tvalidation_0-error:0.23230\n",
      "[230]\tvalidation_0-error:0.23231\n",
      "[231]\tvalidation_0-error:0.23230\n",
      "[232]\tvalidation_0-error:0.23229\n",
      "[233]\tvalidation_0-error:0.23226\n",
      "[234]\tvalidation_0-error:0.23210\n",
      "[235]\tvalidation_0-error:0.23218\n",
      "[236]\tvalidation_0-error:0.23217\n",
      "[237]\tvalidation_0-error:0.23215\n",
      "[238]\tvalidation_0-error:0.23206\n",
      "[239]\tvalidation_0-error:0.23201\n",
      "[240]\tvalidation_0-error:0.23207\n",
      "[241]\tvalidation_0-error:0.23206\n",
      "[242]\tvalidation_0-error:0.23197\n",
      "[243]\tvalidation_0-error:0.23197\n",
      "[244]\tvalidation_0-error:0.23195\n",
      "[245]\tvalidation_0-error:0.23199\n",
      "[246]\tvalidation_0-error:0.23184\n",
      "[247]\tvalidation_0-error:0.23185\n",
      "[248]\tvalidation_0-error:0.23178\n",
      "[249]\tvalidation_0-error:0.23182\n",
      "[250]\tvalidation_0-error:0.23183\n",
      "[251]\tvalidation_0-error:0.23174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[252]\tvalidation_0-error:0.23173\n",
      "[253]\tvalidation_0-error:0.23169\n",
      "[254]\tvalidation_0-error:0.23167\n",
      "[255]\tvalidation_0-error:0.23162\n",
      "[256]\tvalidation_0-error:0.23167\n",
      "[257]\tvalidation_0-error:0.23162\n",
      "[258]\tvalidation_0-error:0.23154\n",
      "[259]\tvalidation_0-error:0.23148\n",
      "[260]\tvalidation_0-error:0.23156\n",
      "[261]\tvalidation_0-error:0.23157\n",
      "[262]\tvalidation_0-error:0.23137\n",
      "[263]\tvalidation_0-error:0.23144\n",
      "[264]\tvalidation_0-error:0.23148\n",
      "[265]\tvalidation_0-error:0.23149\n",
      "[266]\tvalidation_0-error:0.23142\n",
      "[267]\tvalidation_0-error:0.23129\n",
      "[268]\tvalidation_0-error:0.23128\n",
      "[269]\tvalidation_0-error:0.23138\n",
      "[270]\tvalidation_0-error:0.23140\n",
      "[271]\tvalidation_0-error:0.23140\n",
      "[272]\tvalidation_0-error:0.23134\n",
      "[273]\tvalidation_0-error:0.23132\n",
      "[274]\tvalidation_0-error:0.23124\n",
      "[275]\tvalidation_0-error:0.23127\n",
      "[276]\tvalidation_0-error:0.23123\n",
      "[277]\tvalidation_0-error:0.23124\n",
      "[278]\tvalidation_0-error:0.23127\n",
      "[279]\tvalidation_0-error:0.23126\n",
      "[280]\tvalidation_0-error:0.23113\n",
      "[281]\tvalidation_0-error:0.23114\n",
      "[282]\tvalidation_0-error:0.23106\n",
      "[283]\tvalidation_0-error:0.23108\n",
      "[284]\tvalidation_0-error:0.23112\n",
      "[285]\tvalidation_0-error:0.23115\n",
      "[286]\tvalidation_0-error:0.23114\n",
      "[287]\tvalidation_0-error:0.23109\n",
      "[288]\tvalidation_0-error:0.23114\n",
      "[289]\tvalidation_0-error:0.23114\n",
      "[290]\tvalidation_0-error:0.23108\n",
      "[291]\tvalidation_0-error:0.23107\n",
      "[292]\tvalidation_0-error:0.23105\n",
      "[293]\tvalidation_0-error:0.23103\n",
      "[294]\tvalidation_0-error:0.23099\n",
      "[295]\tvalidation_0-error:0.23095\n",
      "[296]\tvalidation_0-error:0.23100\n",
      "[297]\tvalidation_0-error:0.23085\n",
      "[298]\tvalidation_0-error:0.23081\n",
      "[299]\tvalidation_0-error:0.23082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 76.9176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 82.47697000000001\n",
      "235.97069001197815\n",
      "{'test': 0.769176, 'train': 0.8247697, 'taken': 235.97069001197815}\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(tree_method='gpu_hist',\n",
    "                      booster = 'gbtree',\n",
    "                      max_depth = 14,\n",
    "                      n_estimators = 300,\n",
    "                      learning_rate = 0.4,\n",
    "                      reg_lambda=600\n",
    "                     ) # booster = gbtree, dart\n",
    "\n",
    "eval_set = [(x_test_alpha, y_test_alpha)]\n",
    "\n",
    "t0 = time()\n",
    "a = model.fit(x_train_alpha,\n",
    "          y_train_alpha,\n",
    "          eval_metric=\"error\",\n",
    "          eval_set=eval_set,\n",
    "          verbose=True)\n",
    "taken = time()-t0\n",
    "\n",
    "y_test_alpha_pred = model.predict(x_test_alpha,ntree_limit=model.best_ntree_limit)\n",
    "accuracy_test = accuracy_score(y_test_alpha, y_test_alpha_pred)\n",
    "print(\"The testing accuracy\", accuracy_test*100)\n",
    "\n",
    "y_train_alpha_pred=model.predict(x_train_alpha,ntree_limit=model.best_ntree_limit)\n",
    "accuracy_train = accuracy_score(y_train_alpha, y_train_alpha_pred)\n",
    "print(\"The training accuracy\", accuracy_train*100)\n",
    "\n",
    "\n",
    "print(taken)\n",
    "print({\"test\": accuracy_test, \"train\": accuracy_train, \"taken\": taken})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "164312cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy 76.12\n"
     ]
    }
   ],
   "source": [
    "y_test_alpha_pred = model.predict(x_test_alpha,ntree_limit=model.best_ntree_limit)\n",
    "accuracy = accuracy_score(y_test_alpha, y_test_alpha_pred)\n",
    "print(\"The testing accuracy\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2822d9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy 94.29967\n"
     ]
    }
   ],
   "source": [
    "y_train_alpha_pred=model.predict(x_train_alpha,ntree_limit=model.best_ntree_limit)\n",
    "accuracy = accuracy_score(y_train_alpha, y_train_alpha_pred)\n",
    "print(\"The training accuracy\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bac161",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test_alpha, y_test_alpha_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e47562",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2d39745",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"XGBoost.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
