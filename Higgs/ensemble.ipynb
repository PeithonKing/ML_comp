{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d50477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from gc import collect\n",
    "import pandas as pd\n",
    "import os\n",
    "checkpoint_path = \"training_ensemble/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5418ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data=pd.read_csv(\"DataSetNormalised.csv\")\n",
    "df_label=pd.read_csv(\"LabelSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20fe395",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(df_data.iloc[:,1:])\n",
    "y=np.array(df_label.iloc[:,1])\n",
    "x=x.astype(np.float32)\n",
    "x_test=x[10000000:11000000][:]\n",
    "y_test=y[10000000:11000000][:]\n",
    "x_train=x[:1000000][:]\n",
    "y_train=y[:1000000][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77872fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_data\n",
    "del df_label\n",
    "del x\n",
    "del y\n",
    "collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec91354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb=XGBClassifier()\n",
    "model_xgb.load_model(\"XGBoost.json\")\n",
    "y_test_pred_xgb=model_xgb.predict_proba(x_test)\n",
    "y_train_pred_xgb=model_xgb.predict_proba(x_train)\n",
    "y_pred_xgb=y_test_pred_xgb[:,1]\n",
    "y_pred_xgb_train=y_train_pred_xgb[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae9cfae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_xgb=np.reshape(y_pred_xgb,(1000000,1))\n",
    "y_train_pred_xgb=np.reshape(y_pred_xgb_train,(1000000,1))\n",
    "y_train_pred_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c41894c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_sequential_2_layer_call_and_return_conditional_losses_202507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_15_layer_call_and_return_conditional_losses_203133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_14_layer_call_and_return_conditional_losses_203026) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_13_layer_call_and_return_conditional_losses_201541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_200754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_14_layer_call_and_return_conditional_losses_201608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_13_layer_call_and_return_conditional_losses_202919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_15_layer_call_and_return_conditional_losses_201675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_16_layer_call_and_return_conditional_losses_201742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_16_layer_call_and_return_conditional_losses_203240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_12_layer_call_and_return_conditional_losses_201474) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_2_layer_call_and_return_conditional_losses_202658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_12_layer_call_and_return_conditional_losses_202812) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "model_DNN_5 = tf.keras.models.load_model('DNN_5')\n",
    "y_test_pred_DNN_5=model_DNN_5.predict(x_test)\n",
    "y_train_pred_DNN_5=model_DNN_5(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b42f72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_71612) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_72687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_8_layer_call_and_return_conditional_losses_73082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_72772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_8_layer_call_and_return_conditional_losses_72176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "model_NN_Shallow_1024 = tf.keras.models.load_model('NN_Shallow_1024')\n",
    "y_test_pred_NN_Shallow_1024=model_NN_Shallow_1024.predict(x_test)\n",
    "y_train_pred_NN_Shallow_1024=model_NN_Shallow_1024.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3719043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "model_NN_Shallow_2048 = tf.keras.models.load_model('NN_Shallow_2048')\n",
    "y_test_pred_NN_Shallow_2048=model_NN_Shallow_2048.predict(x_test)\n",
    "y_train_pred_NN_Shallow_2048=model_NN_Shallow_2048.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d08bfd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "model_NN_Shallow_10240 = tf.keras.models.load_model('NN_Shallow_10240')\n",
    "y_test_pred_NN_Shallow_10240=model_NN_Shallow_10240.predict(x_test)\n",
    "y_train_pred_NN_Shallow_10240=model_NN_Shallow_10240.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13fb25ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ResNet_52 = tf.keras.models.load_model('ResNet_52')\n",
    "y_test_pred_model_ResNet_52=model_ResNet_52.predict(x_test)\n",
    "y_train_pred_model_ResNet_52=model_ResNet_52.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b261485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrain=pd.DataFrame(x_train)\n",
    "df_entrain['XGB']=y_train_pred_xgb\n",
    "df_entrain['DNN5']=y_train_pred_DNN_5\n",
    "df_entrain['S1024']=y_train_pred_NN_Shallow_1024\n",
    "df_entrain['S2048']=y_train_pred_NN_Shallow_2048\n",
    "df_entrain['10240']=y_train_pred_NN_Shallow_10240\n",
    "df_entrain['RN52']=y_train_pred_model_ResNet_52\n",
    "df_entrain.to_csv(\"Train_ens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a139ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entest=pd.DataFrame(x_test)\n",
    "df_entest['XGB']=y_test_pred_xgb\n",
    "df_entest['DNN5']=y_test_pred_DNN_5\n",
    "df_entest['S1024']=y_test_pred_NN_Shallow_1024\n",
    "df_entest['S2048']=y_test_pred_NN_Shallow_2048\n",
    "df_entest['10240']=y_test_pred_NN_Shallow_10240\n",
    "df_entest['RN52']=y_test_pred_model_ResNet_52\n",
    "df_entest.to_csv(\"Test_ens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47c4043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_en=np.array(df_entest.iloc[:,28:])\n",
    "\n",
    "x_train_en=np.array(df_entrain.iloc[:,28:])\n",
    "x_test_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "569a8bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x12e046f2730>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model.load_weights(latest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a6ab3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512,activation='gelu'),\n",
    "    tf.keras.layers.Dense(512,activation='gelu'),\n",
    "    tf.keras.layers.Dense(128,activation='gelu'),\n",
    "    tf.keras.layers.Dense(128,activation='gelu'),\n",
    "    tf.keras.layers.Dense(10,activation='gelu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f8bbe7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.0001,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy','AUC']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "12ffd448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.8427 - auc: 0.9222\n",
      "Epoch 00001: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 3s 20ms/step - loss: 0.3533 - accuracy: 0.8427 - auc: 0.9222 - val_loss: 0.4812 - val_accuracy: 0.7745 - val_auc: 0.8608\n",
      "Epoch 2/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.8428 - auc: 0.9223\n",
      "Epoch 00002: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3529 - accuracy: 0.8428 - auc: 0.9224 - val_loss: 0.4817 - val_accuracy: 0.7756 - val_auc: 0.8604\n",
      "Epoch 3/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3531 - accuracy: 0.8428 - auc: 0.9223\n",
      "Epoch 00003: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3530 - accuracy: 0.8428 - auc: 0.9223 - val_loss: 0.4841 - val_accuracy: 0.7729 - val_auc: 0.8589\n",
      "Epoch 4/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3527 - accuracy: 0.8429 - auc: 0.9225\n",
      "Epoch 00004: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3528 - accuracy: 0.8429 - auc: 0.9224 - val_loss: 0.4841 - val_accuracy: 0.7729 - val_auc: 0.8575\n",
      "Epoch 5/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.8428 - auc: 0.9224\n",
      "Epoch 00005: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3530 - accuracy: 0.8428 - auc: 0.9224 - val_loss: 0.4806 - val_accuracy: 0.7737 - val_auc: 0.8587\n",
      "Epoch 6/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3540 - accuracy: 0.8425 - auc: 0.9219\n",
      "Epoch 00006: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3540 - accuracy: 0.8425 - auc: 0.9219 - val_loss: 0.4954 - val_accuracy: 0.7753 - val_auc: 0.8619\n",
      "Epoch 7/100\n",
      "95/98 [============================>.] - ETA: 0s - loss: 0.3534 - accuracy: 0.8428 - auc: 0.9222\n",
      "Epoch 00007: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3535 - accuracy: 0.8427 - auc: 0.9221 - val_loss: 0.4841 - val_accuracy: 0.7742 - val_auc: 0.8605\n",
      "Epoch 8/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.8426 - auc: 0.9223\n",
      "Epoch 00008: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3530 - accuracy: 0.8427 - auc: 0.9223 - val_loss: 0.4831 - val_accuracy: 0.7755 - val_auc: 0.8605\n",
      "Epoch 9/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3533 - accuracy: 0.8429 - auc: 0.9222\n",
      "Epoch 00009: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3532 - accuracy: 0.8430 - auc: 0.9223 - val_loss: 0.4914 - val_accuracy: 0.7742 - val_auc: 0.8596\n",
      "Epoch 10/100\n",
      "95/98 [============================>.] - ETA: 0s - loss: 0.3529 - accuracy: 0.8429 - auc: 0.9224\n",
      "Epoch 00010: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3529 - accuracy: 0.8429 - auc: 0.9224 - val_loss: 0.4826 - val_accuracy: 0.7755 - val_auc: 0.8606\n",
      "Epoch 11/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3527 - accuracy: 0.8431 - auc: 0.9224\n",
      "Epoch 00011: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3529 - accuracy: 0.8430 - auc: 0.9224 - val_loss: 0.4800 - val_accuracy: 0.7739 - val_auc: 0.8589\n",
      "Epoch 12/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.8427 - auc: 0.9222\n",
      "Epoch 00012: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 0.3532 - accuracy: 0.8428 - auc: 0.9223 - val_loss: 0.4856 - val_accuracy: 0.7738 - val_auc: 0.8592\n",
      "Epoch 13/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3533 - accuracy: 0.8428 - auc: 0.9222\n",
      "Epoch 00013: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3533 - accuracy: 0.8429 - auc: 0.9222 - val_loss: 0.4848 - val_accuracy: 0.7736 - val_auc: 0.8588\n",
      "Epoch 14/100\n",
      "94/98 [===========================>..] - ETA: 0s - loss: 0.3532 - accuracy: 0.8428 - auc: 0.9222\n",
      "Epoch 00014: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3530 - accuracy: 0.8429 - auc: 0.9223 - val_loss: 0.4880 - val_accuracy: 0.7748 - val_auc: 0.8599\n",
      "Epoch 15/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3525 - accuracy: 0.8430 - auc: 0.9225\n",
      "Epoch 00015: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3526 - accuracy: 0.8430 - auc: 0.9225 - val_loss: 0.4858 - val_accuracy: 0.7748 - val_auc: 0.8596\n",
      "Epoch 16/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.8427 - auc: 0.9224\n",
      "Epoch 00016: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3530 - accuracy: 0.8427 - auc: 0.9224 - val_loss: 0.4891 - val_accuracy: 0.7747 - val_auc: 0.8595\n",
      "Epoch 17/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.8428 - auc: 0.9224\n",
      "Epoch 00017: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3528 - accuracy: 0.8429 - auc: 0.9224 - val_loss: 0.4903 - val_accuracy: 0.7734 - val_auc: 0.8588\n",
      "Epoch 18/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.8429 - auc: 0.9224\n",
      "Epoch 00018: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3528 - accuracy: 0.8428 - auc: 0.9224 - val_loss: 0.4807 - val_accuracy: 0.7750 - val_auc: 0.8600\n",
      "Epoch 19/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3527 - accuracy: 0.8427 - auc: 0.9224\n",
      "Epoch 00019: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3527 - accuracy: 0.8427 - auc: 0.9224 - val_loss: 0.4820 - val_accuracy: 0.7754 - val_auc: 0.8612\n",
      "Epoch 20/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3529 - accuracy: 0.8428 - auc: 0.9224\n",
      "Epoch 00020: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3529 - accuracy: 0.8428 - auc: 0.9224 - val_loss: 0.4890 - val_accuracy: 0.7743 - val_auc: 0.8592\n",
      "Epoch 21/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.8429 - auc: 0.9223\n",
      "Epoch 00021: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3531 - accuracy: 0.8428 - auc: 0.9223 - val_loss: 0.4802 - val_accuracy: 0.7742 - val_auc: 0.8600\n",
      "Epoch 22/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.8429 - auc: 0.9224\n",
      "Epoch 00022: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3528 - accuracy: 0.8429 - auc: 0.9224 - val_loss: 0.4823 - val_accuracy: 0.7731 - val_auc: 0.8591\n",
      "Epoch 23/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.8429 - auc: 0.9223\n",
      "Epoch 00023: saving model to training_ensemble\\cp.ckpt\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.3529 - accuracy: 0.8430 - auc: 0.9224 - val_loss: 0.4824 - val_accuracy: 0.7737 - val_auc: 0.8595\n",
      "Epoch 24/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3527 - accuracy: 0.8430 - auc: 0.9225"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14584/1153896358.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                                  \u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                  verbose=1)\n\u001b[1;32m----> 4\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mx_train_en\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1252\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1253\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    947\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "model.fit(\n",
    "    x_train_en,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=10240,\n",
    "    validation_data=(x_test_en,y_test),\n",
    "    callbacks=[cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a4b9b23e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6,1000000,1) (6,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14584/4265039783.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_test_pred_models\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_test_pred_DNN_5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_pred_model_ResNet_52\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_pred_NN_Shallow_1024\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_pred_NN_Shallow_10240\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_pred_NN_Shallow_2048\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_pred_xgb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpret\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredti\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred_models\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,1000000,1) (6,1) "
     ]
    }
   ],
   "source": [
    "pre_max=np.random.rand(6,1)\n",
    "auc_max=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "99251cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "New Max detected\n",
      "Auc 0.8798746822044039\n",
      "--------------------------------------------\n",
      "New Max detected\n",
      "Auc 0.8800095770975933\n",
      "--------------------------------------------\n",
      "2000\n",
      "3000\n",
      "New Max detected\n",
      "Auc 0.8800408709888439\n",
      "--------------------------------------------\n",
      "4000\n",
      "5000\n",
      "New Max detected\n",
      "Auc 0.8802592341922955\n",
      "--------------------------------------------\n",
      "6000\n",
      "7000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14584/240243628.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0my_pred_ensemble\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred_ensemble\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my_test_pred_xgb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0my_pred_ensemble\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred_ensemble\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_ensemble\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mauc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mauc_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m     \"\"\"\n\u001b[1;32m--> 913\u001b[1;33m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[0;32m    914\u001b[0m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    686\u001b[0m     \"\"\"\n\u001b[0;32m    687\u001b[0m     \u001b[1;31m# Check to make sure y_true is valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m     if not (y_type == \"binary\" or\n\u001b[0;32m    690\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'continuous'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'multiclass'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[1;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "for i in range(10000):\n",
    "    pre=(np.random.rand(6,1))\n",
    "    y_pred_ensemble=y_test_pred_DNN_5*pre[0]\n",
    "    y_pred_ensemble=y_pred_ensemble+y_test_pred_model_ResNet_52*pre[1]\n",
    "    y_pred_ensemble=y_pred_ensemble+y_test_pred_NN_Shallow_1024*pre[2]\n",
    "    y_pred_ensemble=y_pred_ensemble+y_test_pred_NN_Shallow_10240*pre[3]\n",
    "    y_pred_ensemble=y_pred_ensemble+y_test_pred_NN_Shallow_2048*pre[4]\n",
    "    y_pred_ensemble=y_pred_ensemble+y_test_pred_xgb*pre[5]\n",
    "    y_pred_ensemble=y_pred_ensemble/(pre[0]+pre[1]+pre[2]+pre[3]+pre[4]+pre[5])\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_ensemble)\n",
    "    auc=metrics.auc(fpr, tpr)\n",
    "    if auc>auc_max:\n",
    "        auc_max=auc\n",
    "        print(\"New Max detected\")\n",
    "        print(\"Auc\",auc)\n",
    "        print(\"--------------------------------------------\")\n",
    "        pre_max=pre\n",
    "    if i%1000==0:\n",
    "        print(str(i))\n",
    "print(str(t2-t1))\n",
    "\n",
    "#print(\"The training accuracy\",str(accuracy_score(y_test`, np.round(y_pred_ensemble))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0f158b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98742091],\n",
       "       [0.51091043],\n",
       "       [0.40462122],\n",
       "       [0.00178943],\n",
       "       [0.18467257],\n",
       "       [0.17939743]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d2e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying out average ensemble\n",
    "y_pred_ensemble=y_test_pred_DNN_5+0*y_test_pred_NN_Shallow_1024\n",
    "y_pred_ensemble=np.round(y_pred_ensemble)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
    "print(\"The training accuracy\",str(accuracy))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_ensemble)\n",
    "metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f3b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
