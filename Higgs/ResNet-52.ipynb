{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213c9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow.keras\n",
    "import os\n",
    "checkpoint_path = \"training_ResNet_52/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7911d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_rate=0.1 #The rate of droupout for the layers in the ResNet\n",
    "act='gelu'#The activation function use ('relu','swish','elu','gelu','selu')\n",
    "lr=0.001 #The default learning rate Default 0.01\n",
    "mom=0.9 #The momentum parameter Default 0.9\n",
    "test_split=1 #Default 1 and range[1,0)\n",
    "#Reducing test_split will make the model faster but will also reduce the accuracy of the Validation metric\n",
    "#On changing test_split run the lower initialisation cell, marked below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1d9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data=pd.read_csv(\"DataSetNormalised.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7e85e",
   "metadata": {},
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f8de25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label=pd.read_csv(\"LabelSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "233a4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(df_data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26860715",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(df_label.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc6554a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "416810ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On changing test_split run this--------**\n",
    "size=10000000 + test_split*1000000\n",
    "x_train=x[:][:10000000]\n",
    "y_train=y[:][:10000000]\n",
    "x_test=x[:][10000000:size]\n",
    "y_test=y[:][10000000:size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f48792",
   "metadata": {},
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84c77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X,no_nodes,Activation):#A custom Residual identity block with a skip connection\n",
    "    X_shortcut=X\n",
    "    #There will be 3 layers in total for the sequential connection\n",
    "    #Activation will be specified by the user as per the Keras Documentation\n",
    "    #no_nodes denote the size of the model which will be built\n",
    "    #Applying Batch Normalisation to size the inputs\n",
    "    #Layer 1 -----------------------------------------------\n",
    "    X=tf.keras.layers.Dense(no_nodes,activation=Activation)(X)\n",
    "    X=tf.keras.layers.BatchNormalization(axis=1)(X)\n",
    "    X=tf.keras.layers.Dropout(d_rate)(X)\n",
    "    #--------------------------------------------------------\n",
    "    #Layer 2-------------------------------------------------\n",
    "    X=tf.keras.layers.Dense(no_nodes,activation=Activation)(X)\n",
    "    X=tf.keras.layers.BatchNormalization(axis=1)(X)\n",
    "    X=tf.keras.layers.Dropout(d_rate)(X)\n",
    "    #--------------------------------------------------------\n",
    "    #Layer 3-------------------------------------------------\n",
    "    X=tf.keras.layers.Dense(no_nodes,activation=Activation)(X)\n",
    "    X=tf.keras.layers.Dropout(d_rate)(X)\n",
    "    #--------------------------------------------------------\n",
    "    #Layer 4-------------------------------------------------\n",
    "    X= tf.keras.layers.Add()([X_shortcut, X])\n",
    "    X=tf.keras.layers.Activation('relu')(X)\n",
    "    #--------------------------------------------------------\n",
    "    X_shortcut2=X\n",
    "     #Layer 5 -----------------------------------------------\n",
    "    X=tf.keras.layers.Dense(no_nodes,activation=Activation)(X)\n",
    "    X=tf.keras.layers.BatchNormalization(axis=1)(X)\n",
    "    X=tf.keras.layers.Dropout(d_rate)(X)\n",
    "    #--------------------------------------------------------\n",
    "    #Layer 6-------------------------------------------------\n",
    "    X=tf.keras.layers.Dense(no_nodes,activation=Activation)(X)\n",
    "    X=tf.keras.layers.BatchNormalization(axis=1)(X)\n",
    "    X=tf.keras.layers.Dropout(d_rate)(X)\n",
    "    #--------------------------------------------------------\n",
    "    #Layer 7-------------------------------------------------\n",
    "    X=tf.keras.layers.Dense(no_nodes,activation=Activation)(X)\n",
    "    X=tf.keras.layers.Dropout(d_rate)(X)\n",
    "    #--------------------------------------------------------\n",
    "    X= tf.keras.layers.Add()([X_shortcut, X,X_shortcut2])\n",
    "    #Layer 8-------------------------------------------------\n",
    "    X=tf.keras.layers.Activation('relu')(X)\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc516b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tf.keras.layers.Input(shape=(28,))                    #Keras input layer\n",
    "X=tf.keras.layers.Dense(300,activation=act)(inputs)\n",
    "X=identity_block(X=X,no_nodes=300,Activation=act)\n",
    "X=identity_block(X=X,no_nodes=300,Activation=act)\n",
    "X=identity_block(X=X,no_nodes=300,Activation=act)\n",
    "X=identity_block(X=X,no_nodes=300,Activation=act)\n",
    "X=identity_block(X=X,no_nodes=300,Activation=act)        \n",
    "outputs=tf.keras.layers.Dense(1,activation='sigmoid')(X)     #keras output layer\n",
    "model=tf.keras.Model(inputs,outputs)                         #Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f4a8788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 300)          8700        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 300)          90300       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 300)         1200        ['dense_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 300)          0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 300)          90300       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 300)         1200        ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 300)          0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 300)          90300       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 300)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 300)          0           ['dense[0][0]',                  \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 300)          0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 300)          90300       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 300)         1200        ['dense_4[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 300)          0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 300)          90300       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 300)         1200        ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 300)          0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 300)          90300       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 300)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 300)          0           ['dense[0][0]',                  \n",
      "                                                                  'dropout_5[0][0]',              \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 300)          0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 300)          90300       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 300)         1200        ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 300)          0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 300)          90300       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 300)         1200        ['dense_8[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 300)          0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 300)          90300       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 300)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 300)          0           ['activation_1[0][0]',           \n",
      "                                                                  'dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 300)          0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 300)          90300       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 300)         1200        ['dense_10[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 300)          0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 300)          90300       ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 300)         1200        ['dense_11[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 300)          0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 300)          90300       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 300)          0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 300)          0           ['activation_1[0][0]',           \n",
      "                                                                  'dropout_11[0][0]',             \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 300)          0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 300)          90300       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 300)         1200        ['dense_13[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 300)          0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 300)          90300       ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 300)         1200        ['dense_14[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 300)          0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 300)          90300       ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 300)          0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 300)          0           ['activation_3[0][0]',           \n",
      "                                                                  'dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 300)          0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 300)          90300       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 300)         1200        ['dense_16[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 300)          0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 300)          90300       ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 300)         1200        ['dense_17[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 300)          0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 300)          90300       ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 300)          0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 300)          0           ['activation_3[0][0]',           \n",
      "                                                                  'dropout_17[0][0]',             \n",
      "                                                                  'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 300)          0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 300)          90300       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 300)         1200        ['dense_19[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 300)          0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 300)          90300       ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 300)         1200        ['dense_20[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 300)          0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 300)          90300       ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 300)          0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 300)          0           ['activation_5[0][0]',           \n",
      "                                                                  'dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 300)          0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 300)          90300       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 300)         1200        ['dense_22[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 300)          0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 300)          90300       ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 300)         1200        ['dense_23[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 300)          0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 300)          90300       ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 300)          0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 300)          0           ['activation_5[0][0]',           \n",
      "                                                                  'dropout_23[0][0]',             \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 300)          0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 300)          90300       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 300)         1200        ['dense_25[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 300)          0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 300)          90300       ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 300)         1200        ['dense_26[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 300)          0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 300)          90300       ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 300)          0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 300)          0           ['activation_7[0][0]',           \n",
      "                                                                  'dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 300)          0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 300)          90300       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 300)         1200        ['dense_28[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 300)          0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 300)          90300       ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 300)         1200        ['dense_29[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 300)          0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 300)          90300       ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 300)          0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 300)          0           ['activation_7[0][0]',           \n",
      "                                                                  'dropout_29[0][0]',             \n",
      "                                                                  'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 300)          0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 1)            301         ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,742,001\n",
      "Trainable params: 2,730,001\n",
      "Non-trainable params: 12,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f5eb2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.01,\n",
    "        beta_1=mom,\n",
    "        beta_2=0.999),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy','AUC']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64c81210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x18634c499d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c89121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HostLog(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        with open(\"log3.txt\", \"a\") as f:\n",
    "            f.write(f\"at epoch {epoch}:{str(logs)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398541ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  6/977 [..............................] - ETA: 3:59 - loss: 0.4441 - accuracy: 0.7871 - auc: 0.8716WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1208s vs `on_train_batch_end` time: 0.1257s). Check your callbacks.\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.7853 - auc: 0.8709\n",
      "Epoch 00001: val_loss improved from inf to 2.16567, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 252s 249ms/step - loss: 0.4452 - accuracy: 0.7853 - auc: 0.8709 - val_loss: 2.1657 - val_accuracy: 0.7846 - val_auc: 0.8701 - lr: 6.0025e-04\n",
      "Epoch 2/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.7852 - auc: 0.8710\n",
      "Epoch 00002: val_loss improved from 2.16567 to 0.89279, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4451 - accuracy: 0.7852 - auc: 0.8710 - val_loss: 0.8928 - val_accuracy: 0.7845 - val_auc: 0.8700 - lr: 6.0025e-04\n",
      "Epoch 3/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.7854 - auc: 0.8711\n",
      "Epoch 00003: val_loss improved from 0.89279 to 0.52051, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 243s 248ms/step - loss: 0.4449 - accuracy: 0.7854 - auc: 0.8711 - val_loss: 0.5205 - val_accuracy: 0.7839 - val_auc: 0.8697 - lr: 6.0025e-04\n",
      "Epoch 4/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4450 - accuracy: 0.7855 - auc: 0.8711\n",
      "Epoch 00004: val_loss did not improve from 0.52051\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4450 - accuracy: 0.7855 - auc: 0.8711 - val_loss: 4.0353 - val_accuracy: 0.7846 - val_auc: 0.8701 - lr: 6.0025e-04\n",
      "Epoch 5/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.7856 - auc: 0.8711\n",
      "Epoch 00005: val_loss did not improve from 0.52051\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4449 - accuracy: 0.7856 - auc: 0.8711 - val_loss: 0.6831 - val_accuracy: 0.7844 - val_auc: 0.8699 - lr: 6.0025e-04\n",
      "Epoch 6/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4448 - accuracy: 0.7854 - auc: 0.8712\n",
      "Epoch 00006: val_loss did not improve from 0.52051\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4448 - accuracy: 0.7854 - auc: 0.8712 - val_loss: 54096.6602 - val_accuracy: 0.7844 - val_auc: 0.8698 - lr: 6.0025e-04\n",
      "Epoch 7/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.7855 - auc: 0.8712\n",
      "Epoch 00007: val_loss did not improve from 0.52051\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4447 - accuracy: 0.7855 - auc: 0.8712 - val_loss: 0.9731 - val_accuracy: 0.7839 - val_auc: 0.8696 - lr: 6.0025e-04\n",
      "Epoch 8/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4445 - accuracy: 0.7857 - auc: 0.8714\n",
      "Epoch 00008: val_loss improved from 0.52051 to 0.44669, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 243s 248ms/step - loss: 0.4445 - accuracy: 0.7857 - auc: 0.8714 - val_loss: 0.4467 - val_accuracy: 0.7845 - val_auc: 0.8700 - lr: 6.0025e-04\n",
      "Epoch 9/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4445 - accuracy: 0.7857 - auc: 0.8714\n",
      "Epoch 00009: val_loss did not improve from 0.44669\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4445 - accuracy: 0.7857 - auc: 0.8714 - val_loss: 2.5455 - val_accuracy: 0.7843 - val_auc: 0.8699 - lr: 6.0025e-04\n",
      "Epoch 10/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4444 - accuracy: 0.7857 - auc: 0.8714\n",
      "Epoch 00010: val_loss did not improve from 0.44669\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4444 - accuracy: 0.7857 - auc: 0.8714 - val_loss: 0.4871 - val_accuracy: 0.7845 - val_auc: 0.8702 - lr: 6.0025e-04\n",
      "Epoch 11/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.7859 - auc: 0.8715\n",
      "Epoch 00011: val_loss did not improve from 0.44669\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4443 - accuracy: 0.7859 - auc: 0.8715 - val_loss: 0.4838 - val_accuracy: 0.7847 - val_auc: 0.8701 - lr: 6.0025e-04\n",
      "Epoch 12/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.7857 - auc: 0.8714\n",
      "Epoch 00012: val_loss did not improve from 0.44669\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4443 - accuracy: 0.7857 - auc: 0.8714 - val_loss: 42840.0977 - val_accuracy: 0.7845 - val_auc: 0.8702 - lr: 6.0025e-04\n",
      "Epoch 13/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4442 - accuracy: 0.7859 - auc: 0.8716\n",
      "Epoch 00013: val_loss did not improve from 0.44669\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4442 - accuracy: 0.7859 - auc: 0.8716 - val_loss: 0.4469 - val_accuracy: 0.7847 - val_auc: 0.8700 - lr: 6.0025e-04\n",
      "Epoch 14/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.7862 - auc: 0.8719\n",
      "Epoch 00014: val_loss did not improve from 0.44669\n",
      "977/977 [==============================] - 245s 251ms/step - loss: 0.4437 - accuracy: 0.7862 - auc: 0.8719 - val_loss: 0.4641 - val_accuracy: 0.7850 - val_auc: 0.8705 - lr: 4.2018e-04\n",
      "Epoch 15/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.7862 - auc: 0.8720\n",
      "Epoch 00015: val_loss did not improve from 0.44669\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4435 - accuracy: 0.7862 - auc: 0.8720 - val_loss: 0.5063 - val_accuracy: 0.7848 - val_auc: 0.8703 - lr: 4.2018e-04\n",
      "Epoch 16/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.7863 - auc: 0.8720\n",
      "Epoch 00016: val_loss did not improve from 0.44669\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4435 - accuracy: 0.7863 - auc: 0.8720 - val_loss: 0.4694 - val_accuracy: 0.7848 - val_auc: 0.8704 - lr: 4.2018e-04\n",
      "Epoch 17/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.7864 - auc: 0.8721\n",
      "Epoch 00017: val_loss did not improve from 0.44669\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4434 - accuracy: 0.7864 - auc: 0.8721 - val_loss: 0.4497 - val_accuracy: 0.7847 - val_auc: 0.8705 - lr: 4.2018e-04\n",
      "Epoch 18/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.7864 - auc: 0.8721\n",
      "Epoch 00018: val_loss improved from 0.44669 to 0.44623, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 243s 248ms/step - loss: 0.4434 - accuracy: 0.7864 - auc: 0.8721 - val_loss: 0.4462 - val_accuracy: 0.7850 - val_auc: 0.8705 - lr: 4.2018e-04\n",
      "Epoch 19/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4433 - accuracy: 0.7865 - auc: 0.8721\n",
      "Epoch 00019: val_loss did not improve from 0.44623\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4433 - accuracy: 0.7865 - auc: 0.8721 - val_loss: 0.8141 - val_accuracy: 0.7846 - val_auc: 0.8702 - lr: 4.2018e-04\n",
      "Epoch 20/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.7864 - auc: 0.8722\n",
      "Epoch 00020: val_loss did not improve from 0.44623\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4432 - accuracy: 0.7864 - auc: 0.8722 - val_loss: 0.5030 - val_accuracy: 0.7844 - val_auc: 0.8704 - lr: 4.2018e-04\n",
      "INFO:tensorflow:Assets written to: ResNet_52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  6/977 [..............................] - ETA: 3:59 - loss: 0.4422 - accuracy: 0.7872 - auc: 0.8732WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1197s vs `on_train_batch_end` time: 0.1268s). Check your callbacks.\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.7865 - auc: 0.8722\n",
      "Epoch 00001: val_loss improved from inf to 0.55537, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 243s 248ms/step - loss: 0.4432 - accuracy: 0.7865 - auc: 0.8722 - val_loss: 0.5554 - val_accuracy: 0.7847 - val_auc: 0.8702 - lr: 4.2018e-04\n",
      "Epoch 2/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.7866 - auc: 0.8723\n",
      "Epoch 00002: val_loss improved from 0.55537 to 0.44625, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4430 - accuracy: 0.7866 - auc: 0.8723 - val_loss: 0.4463 - val_accuracy: 0.7849 - val_auc: 0.8703 - lr: 4.2018e-04\n",
      "Epoch 3/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4429 - accuracy: 0.7867 - auc: 0.8724\n",
      "Epoch 00003: val_loss did not improve from 0.44625\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4429 - accuracy: 0.7867 - auc: 0.8724 - val_loss: 0.4883 - val_accuracy: 0.7850 - val_auc: 0.8705 - lr: 4.2018e-04\n",
      "Epoch 4/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.7866 - auc: 0.8723\n",
      "Epoch 00004: val_loss improved from 0.44625 to 0.44604, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4430 - accuracy: 0.7866 - auc: 0.8723 - val_loss: 0.4460 - val_accuracy: 0.7851 - val_auc: 0.8706 - lr: 4.2018e-04\n",
      "Epoch 5/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.7867 - auc: 0.8724\n",
      "Epoch 00005: val_loss did not improve from 0.44604\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4428 - accuracy: 0.7867 - auc: 0.8724 - val_loss: 705.1889 - val_accuracy: 0.7850 - val_auc: 0.8705 - lr: 4.2018e-04\n",
      "Epoch 6/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.7867 - auc: 0.8724\n",
      "Epoch 00006: val_loss did not improve from 0.44604\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4428 - accuracy: 0.7867 - auc: 0.8724 - val_loss: 0.4462 - val_accuracy: 0.7849 - val_auc: 0.8704 - lr: 4.2018e-04\n",
      "Epoch 7/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4429 - accuracy: 0.7867 - auc: 0.8724\n",
      "Epoch 00007: val_loss did not improve from 0.44604\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4429 - accuracy: 0.7867 - auc: 0.8724 - val_loss: 339.0149 - val_accuracy: 0.7840 - val_auc: 0.8700 - lr: 4.2018e-04\n",
      "Epoch 8/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.7867 - auc: 0.8724\n",
      "Epoch 00008: val_loss did not improve from 0.44604\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4428 - accuracy: 0.7867 - auc: 0.8724 - val_loss: 0.4588 - val_accuracy: 0.7849 - val_auc: 0.8705 - lr: 4.2018e-04\n",
      "Epoch 9/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4424 - accuracy: 0.7870 - auc: 0.8727\n",
      "Epoch 00009: val_loss improved from 0.44604 to 0.44589, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4424 - accuracy: 0.7870 - auc: 0.8727 - val_loss: 0.4459 - val_accuracy: 0.7851 - val_auc: 0.8706 - lr: 2.9412e-04\n",
      "Epoch 10/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.7871 - auc: 0.8728\n",
      "Epoch 00010: val_loss did not improve from 0.44589\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4422 - accuracy: 0.7871 - auc: 0.8728 - val_loss: 2013.9617 - val_accuracy: 0.7849 - val_auc: 0.8705 - lr: 2.9412e-04\n",
      "Epoch 11/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.7870 - auc: 0.8728\n",
      "Epoch 00011: val_loss improved from 0.44589 to 0.44577, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4422 - accuracy: 0.7870 - auc: 0.8728 - val_loss: 0.4458 - val_accuracy: 0.7853 - val_auc: 0.8707 - lr: 2.9412e-04\n",
      "Epoch 12/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.7869 - auc: 0.8728\n",
      "Epoch 00012: val_loss did not improve from 0.44577\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4422 - accuracy: 0.7869 - auc: 0.8728 - val_loss: 0.4670 - val_accuracy: 0.7848 - val_auc: 0.8702 - lr: 2.9412e-04\n",
      "Epoch 13/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.7871 - auc: 0.8728\n",
      "Epoch 00013: val_loss did not improve from 0.44577\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4422 - accuracy: 0.7871 - auc: 0.8728 - val_loss: 9409.1250 - val_accuracy: 0.7848 - val_auc: 0.8706 - lr: 2.9412e-04\n",
      "Epoch 14/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.7872 - auc: 0.8729\n",
      "Epoch 00014: val_loss did not improve from 0.44577\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4421 - accuracy: 0.7872 - auc: 0.8729 - val_loss: 47316.9688 - val_accuracy: 0.7851 - val_auc: 0.8707 - lr: 2.9412e-04\n",
      "Epoch 15/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4420 - accuracy: 0.7872 - auc: 0.8729\n",
      "Epoch 00015: val_loss did not improve from 0.44577\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4420 - accuracy: 0.7872 - auc: 0.8729 - val_loss: 2774.4844 - val_accuracy: 0.7852 - val_auc: 0.8706 - lr: 2.9412e-04\n",
      "Epoch 16/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4420 - accuracy: 0.7872 - auc: 0.8729\n",
      "Epoch 00016: val_loss did not improve from 0.44577\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4420 - accuracy: 0.7872 - auc: 0.8729 - val_loss: 1805.3295 - val_accuracy: 0.7848 - val_auc: 0.8707 - lr: 2.9412e-04\n",
      "Epoch 17/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.7873 - auc: 0.8730\n",
      "Epoch 00017: val_loss did not improve from 0.44577\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4419 - accuracy: 0.7873 - auc: 0.8730 - val_loss: 9863.8809 - val_accuracy: 0.7850 - val_auc: 0.8707 - lr: 2.9412e-04\n",
      "Epoch 18/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.7873 - auc: 0.8730\n",
      "Epoch 00018: val_loss did not improve from 0.44577\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4419 - accuracy: 0.7873 - auc: 0.8730 - val_loss: 0.4460 - val_accuracy: 0.7851 - val_auc: 0.8706 - lr: 2.9412e-04\n",
      "Epoch 19/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.7873 - auc: 0.8730\n",
      "Epoch 00019: val_loss did not improve from 0.44577\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4419 - accuracy: 0.7873 - auc: 0.8730 - val_loss: 28813.5605 - val_accuracy: 0.7854 - val_auc: 0.8708 - lr: 2.9412e-04\n",
      "Epoch 20/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.7874 - auc: 0.8730\n",
      "Epoch 00020: val_loss improved from 0.44577 to 0.44556, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4418 - accuracy: 0.7874 - auc: 0.8730 - val_loss: 0.4456 - val_accuracy: 0.7854 - val_auc: 0.8708 - lr: 2.9412e-04\n",
      "INFO:tensorflow:Assets written to: ResNet_52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  6/977 [..............................] - ETA: 3:56 - loss: 0.4398 - accuracy: 0.7893 - auc: 0.8744WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1181s vs `on_train_batch_end` time: 0.1281s). Check your callbacks.\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.7874 - auc: 0.8731\n",
      "Epoch 00001: val_loss improved from inf to 0.52425, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 243s 248ms/step - loss: 0.4418 - accuracy: 0.7874 - auc: 0.8731 - val_loss: 0.5243 - val_accuracy: 0.7852 - val_auc: 0.8707 - lr: 2.9412e-04\n",
      "Epoch 2/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.7873 - auc: 0.8731\n",
      "Epoch 00002: val_loss improved from 0.52425 to 0.47132, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4418 - accuracy: 0.7873 - auc: 0.8731 - val_loss: 0.4713 - val_accuracy: 0.7848 - val_auc: 0.8704 - lr: 2.9412e-04\n",
      "Epoch 3/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4417 - accuracy: 0.7873 - auc: 0.8731\n",
      "Epoch 00003: val_loss did not improve from 0.47132\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4417 - accuracy: 0.7873 - auc: 0.8731 - val_loss: 1.4697 - val_accuracy: 0.7851 - val_auc: 0.8706 - lr: 2.9412e-04\n",
      "Epoch 4/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.7874 - auc: 0.8732\n",
      "Epoch 00004: val_loss improved from 0.47132 to 0.45314, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4416 - accuracy: 0.7874 - auc: 0.8732 - val_loss: 0.4531 - val_accuracy: 0.7853 - val_auc: 0.8706 - lr: 2.9412e-04\n",
      "Epoch 5/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4417 - accuracy: 0.7874 - auc: 0.8731\n",
      "Epoch 00005: val_loss did not improve from 0.45314\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4417 - accuracy: 0.7874 - auc: 0.8731 - val_loss: 0.6699 - val_accuracy: 0.7850 - val_auc: 0.8706 - lr: 2.9412e-04\n",
      "Epoch 6/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.7874 - auc: 0.8732\n",
      "Epoch 00006: val_loss did not improve from 0.45314\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4416 - accuracy: 0.7874 - auc: 0.8732 - val_loss: 2.0640 - val_accuracy: 0.7853 - val_auc: 0.8706 - lr: 2.9412e-04\n",
      "Epoch 7/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.7874 - auc: 0.8732\n",
      "Epoch 00007: val_loss improved from 0.45314 to 0.44563, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4415 - accuracy: 0.7874 - auc: 0.8732 - val_loss: 0.4456 - val_accuracy: 0.7853 - val_auc: 0.8708 - lr: 2.9412e-04\n",
      "Epoch 8/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.7874 - auc: 0.8732\n",
      "Epoch 00008: val_loss did not improve from 0.44563\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4415 - accuracy: 0.7874 - auc: 0.8732 - val_loss: 1.0034 - val_accuracy: 0.7853 - val_auc: 0.8708 - lr: 2.9412e-04\n",
      "Epoch 9/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.7876 - auc: 0.8733\n",
      "Epoch 00009: val_loss did not improve from 0.44563\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4415 - accuracy: 0.7876 - auc: 0.8733 - val_loss: 0.7336 - val_accuracy: 0.7851 - val_auc: 0.8705 - lr: 2.9412e-04\n",
      "Epoch 10/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4414 - accuracy: 0.7876 - auc: 0.8733\n",
      "Epoch 00010: val_loss did not improve from 0.44563\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4414 - accuracy: 0.7876 - auc: 0.8733 - val_loss: 0.5090 - val_accuracy: 0.7851 - val_auc: 0.8706 - lr: 2.9412e-04\n",
      "Epoch 11/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.7876 - auc: 0.8734\n",
      "Epoch 00011: val_loss did not improve from 0.44563\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4413 - accuracy: 0.7876 - auc: 0.8734 - val_loss: 0.4474 - val_accuracy: 0.7852 - val_auc: 0.8706 - lr: 2.9412e-04\n",
      "Epoch 12/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.7876 - auc: 0.8734\n",
      "Epoch 00012: val_loss did not improve from 0.44563\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4413 - accuracy: 0.7876 - auc: 0.8734 - val_loss: 4.7290 - val_accuracy: 0.7849 - val_auc: 0.8705 - lr: 2.9412e-04\n",
      "Epoch 13/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.7878 - auc: 0.8735\n",
      "Epoch 00013: val_loss did not improve from 0.44563\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4411 - accuracy: 0.7878 - auc: 0.8735 - val_loss: 0.4459 - val_accuracy: 0.7852 - val_auc: 0.8707 - lr: 2.0589e-04\n",
      "Epoch 14/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4410 - accuracy: 0.7878 - auc: 0.8736\n",
      "Epoch 00014: val_loss did not improve from 0.44563\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4410 - accuracy: 0.7878 - auc: 0.8736 - val_loss: 4.4187 - val_accuracy: 0.7854 - val_auc: 0.8708 - lr: 2.0589e-04\n",
      "Epoch 15/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.7879 - auc: 0.8736\n",
      "Epoch 00015: val_loss did not improve from 0.44563\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4409 - accuracy: 0.7879 - auc: 0.8736 - val_loss: 0.6104 - val_accuracy: 0.7853 - val_auc: 0.8708 - lr: 2.0589e-04\n",
      "Epoch 16/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.7878 - auc: 0.8736\n",
      "Epoch 00016: val_loss did not improve from 0.44563\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4409 - accuracy: 0.7878 - auc: 0.8736 - val_loss: 0.8137 - val_accuracy: 0.7855 - val_auc: 0.8709 - lr: 2.0589e-04\n",
      "Epoch 17/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.7878 - auc: 0.8737\n",
      "Epoch 00017: val_loss did not improve from 0.44563\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4409 - accuracy: 0.7878 - auc: 0.8737 - val_loss: 4795.7095 - val_accuracy: 0.7854 - val_auc: 0.8708 - lr: 2.0589e-04\n",
      "Epoch 18/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.7879 - auc: 0.8736\n",
      "Epoch 00018: val_loss improved from 0.44563 to 0.44557, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4409 - accuracy: 0.7879 - auc: 0.8736 - val_loss: 0.4456 - val_accuracy: 0.7853 - val_auc: 0.8708 - lr: 2.0589e-04\n",
      "Epoch 19/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.7879 - auc: 0.8737\n",
      "Epoch 00019: val_loss did not improve from 0.44557\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4409 - accuracy: 0.7879 - auc: 0.8737 - val_loss: 0.4457 - val_accuracy: 0.7853 - val_auc: 0.8708 - lr: 2.0589e-04\n",
      "Epoch 20/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.7879 - auc: 0.8737\n",
      "Epoch 00020: val_loss did not improve from 0.44557\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4408 - accuracy: 0.7879 - auc: 0.8737 - val_loss: 48820.5273 - val_accuracy: 0.7852 - val_auc: 0.8707 - lr: 2.0589e-04\n",
      "INFO:tensorflow:Assets written to: ResNet_52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.7880 - auc: 0.8736\n",
      "Epoch 00001: val_loss improved from inf to 0.44567, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 243s 248ms/step - loss: 0.4409 - accuracy: 0.7880 - auc: 0.8736 - val_loss: 0.4457 - val_accuracy: 0.7853 - val_auc: 0.8707 - lr: 2.0589e-04\n",
      "Epoch 2/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.7880 - auc: 0.8738\n",
      "Epoch 00002: val_loss did not improve from 0.44567\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4407 - accuracy: 0.7880 - auc: 0.8738 - val_loss: 0.4461 - val_accuracy: 0.7850 - val_auc: 0.8707 - lr: 2.0589e-04\n",
      "Epoch 3/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.7879 - auc: 0.8737\n",
      "Epoch 00003: val_loss did not improve from 0.44567\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4408 - accuracy: 0.7879 - auc: 0.8737 - val_loss: 0.4458 - val_accuracy: 0.7851 - val_auc: 0.8708 - lr: 2.0589e-04\n",
      "Epoch 4/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.7880 - auc: 0.8738\n",
      "Epoch 00004: val_loss improved from 0.44567 to 0.44566, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4407 - accuracy: 0.7880 - auc: 0.8738 - val_loss: 0.4457 - val_accuracy: 0.7852 - val_auc: 0.8707 - lr: 2.0589e-04\n",
      "Epoch 5/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.7880 - auc: 0.8737\n",
      "Epoch 00005: val_loss did not improve from 0.44566\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4408 - accuracy: 0.7880 - auc: 0.8737 - val_loss: 0.4458 - val_accuracy: 0.7853 - val_auc: 0.8708 - lr: 2.0589e-04\n",
      "Epoch 6/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.7879 - auc: 0.8738\n",
      "Epoch 00006: val_loss improved from 0.44566 to 0.44550, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4407 - accuracy: 0.7879 - auc: 0.8738 - val_loss: 0.4455 - val_accuracy: 0.7853 - val_auc: 0.8708 - lr: 2.0589e-04\n",
      "Epoch 7/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4404 - accuracy: 0.7882 - auc: 0.8739\n",
      "Epoch 00007: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4404 - accuracy: 0.7882 - auc: 0.8739 - val_loss: 149424.5469 - val_accuracy: 0.7855 - val_auc: 0.8708 - lr: 1.4412e-04\n",
      "Epoch 8/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4404 - accuracy: 0.7881 - auc: 0.8739\n",
      "Epoch 00008: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4404 - accuracy: 0.7881 - auc: 0.8739 - val_loss: 0.4456 - val_accuracy: 0.7854 - val_auc: 0.8709 - lr: 1.4412e-04\n",
      "Epoch 9/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4404 - accuracy: 0.7882 - auc: 0.8740\n",
      "Epoch 00009: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4404 - accuracy: 0.7882 - auc: 0.8740 - val_loss: 5256.9302 - val_accuracy: 0.7854 - val_auc: 0.8709 - lr: 1.4412e-04\n",
      "Epoch 10/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4404 - accuracy: 0.7881 - auc: 0.8740\n",
      "Epoch 00010: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4404 - accuracy: 0.7881 - auc: 0.8740 - val_loss: 3.7874 - val_accuracy: 0.7854 - val_auc: 0.8709 - lr: 1.4412e-04\n",
      "Epoch 11/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.7882 - auc: 0.8740\n",
      "Epoch 00011: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4403 - accuracy: 0.7882 - auc: 0.8740 - val_loss: 0.4474 - val_accuracy: 0.7853 - val_auc: 0.8708 - lr: 1.4412e-04\n",
      "Epoch 12/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.7883 - auc: 0.8741\n",
      "Epoch 00012: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4402 - accuracy: 0.7883 - auc: 0.8741 - val_loss: 0.4455 - val_accuracy: 0.7856 - val_auc: 0.8709 - lr: 1.4412e-04\n",
      "Epoch 13/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.7884 - auc: 0.8741\n",
      "Epoch 00013: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4402 - accuracy: 0.7884 - auc: 0.8741 - val_loss: 0.6183 - val_accuracy: 0.7852 - val_auc: 0.8708 - lr: 1.4412e-04\n",
      "Epoch 14/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.7882 - auc: 0.8740\n",
      "Epoch 00014: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4403 - accuracy: 0.7882 - auc: 0.8740 - val_loss: 32934.7812 - val_accuracy: 0.7853 - val_auc: 0.8708 - lr: 1.4412e-04\n",
      "Epoch 15/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.7884 - auc: 0.8741\n",
      "Epoch 00015: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 247ms/step - loss: 0.4401 - accuracy: 0.7884 - auc: 0.8741 - val_loss: 73.6753 - val_accuracy: 0.7854 - val_auc: 0.8709 - lr: 1.4412e-04\n",
      "Epoch 16/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.7884 - auc: 0.8741\n",
      "Epoch 00016: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4402 - accuracy: 0.7884 - auc: 0.8741 - val_loss: 216.6397 - val_accuracy: 0.7854 - val_auc: 0.8709 - lr: 1.4412e-04\n",
      "Epoch 17/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.7883 - auc: 0.8741\n",
      "Epoch 00017: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4402 - accuracy: 0.7883 - auc: 0.8741 - val_loss: 0.4457 - val_accuracy: 0.7854 - val_auc: 0.8708 - lr: 1.4412e-04\n",
      "Epoch 18/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.7883 - auc: 0.8741\n",
      "Epoch 00018: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 243s 248ms/step - loss: 0.4401 - accuracy: 0.7883 - auc: 0.8741 - val_loss: 2.1716 - val_accuracy: 0.7852 - val_auc: 0.8709 - lr: 1.4412e-04\n",
      "Epoch 19/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.7883 - auc: 0.8741\n",
      "Epoch 00019: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4402 - accuracy: 0.7883 - auc: 0.8741 - val_loss: 0.5684 - val_accuracy: 0.7853 - val_auc: 0.8708 - lr: 1.4412e-04\n",
      "Epoch 20/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.7884 - auc: 0.8741\n",
      "Epoch 00020: val_loss did not improve from 0.44550\n",
      "977/977 [==============================] - 243s 249ms/step - loss: 0.4401 - accuracy: 0.7884 - auc: 0.8741 - val_loss: 1.0456 - val_accuracy: 0.7853 - val_auc: 0.8709 - lr: 1.4412e-04\n",
      "INFO:tensorflow:Assets written to: ResNet_52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\ML_RTC\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  6/977 [..............................] - ETA: 3:58 - loss: 0.4388 - accuracy: 0.7885 - auc: 0.8749WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1175s vs `on_train_batch_end` time: 0.1276s). Check your callbacks.\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.7885 - auc: 0.8743\n",
      "Epoch 00001: val_loss improved from inf to 0.47775, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 243s 248ms/step - loss: 0.4399 - accuracy: 0.7885 - auc: 0.8743 - val_loss: 0.4777 - val_accuracy: 0.7855 - val_auc: 0.8709 - lr: 1.0088e-04\n",
      "Epoch 2/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.7884 - auc: 0.8742\n",
      "Epoch 00002: val_loss did not improve from 0.47775\n",
      "977/977 [==============================] - 241s 247ms/step - loss: 0.4401 - accuracy: 0.7884 - auc: 0.8742 - val_loss: 1.1941 - val_accuracy: 0.7855 - val_auc: 0.8710 - lr: 1.0088e-04\n",
      "Epoch 3/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.7884 - auc: 0.8742\n",
      "Epoch 00003: val_loss did not improve from 0.47775\n",
      "977/977 [==============================] - 242s 248ms/step - loss: 0.4400 - accuracy: 0.7884 - auc: 0.8742 - val_loss: 1.1064 - val_accuracy: 0.7854 - val_auc: 0.8709 - lr: 1.0088e-04\n",
      "Epoch 4/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.7884 - auc: 0.8742\n",
      "Epoch 00004: val_loss did not improve from 0.47775\n",
      "977/977 [==============================] - 248s 254ms/step - loss: 0.4400 - accuracy: 0.7884 - auc: 0.8742 - val_loss: 11.3778 - val_accuracy: 0.7853 - val_auc: 0.8709 - lr: 1.0088e-04\n",
      "Epoch 5/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.7885 - auc: 0.8743\n",
      "Epoch 00005: val_loss did not improve from 0.47775\n",
      "977/977 [==============================] - 247s 253ms/step - loss: 0.4399 - accuracy: 0.7885 - auc: 0.8743 - val_loss: 2.4113 - val_accuracy: 0.7854 - val_auc: 0.8709 - lr: 1.0088e-04\n",
      "Epoch 6/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.7885 - auc: 0.8743\n",
      "Epoch 00006: val_loss improved from 0.47775 to 0.44552, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 244s 249ms/step - loss: 0.4399 - accuracy: 0.7885 - auc: 0.8743 - val_loss: 0.4455 - val_accuracy: 0.7853 - val_auc: 0.8709 - lr: 1.0088e-04\n",
      "Epoch 7/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.7885 - auc: 0.8743\n",
      "Epoch 00007: val_loss did not improve from 0.44552\n",
      "977/977 [==============================] - 243s 248ms/step - loss: 0.4399 - accuracy: 0.7885 - auc: 0.8743 - val_loss: 42215.1914 - val_accuracy: 0.7855 - val_auc: 0.8710 - lr: 1.0088e-04\n",
      "Epoch 8/20\n",
      "977/977 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.7886 - auc: 0.8743\n",
      "Epoch 00008: val_loss improved from 0.44552 to 0.44548, saving model to training_ResNet_52\\cp.ckpt\n",
      "977/977 [==============================] - 243s 249ms/step - loss: 0.4398 - accuracy: 0.7886 - auc: 0.8743 - val_loss: 0.4455 - val_accuracy: 0.7854 - val_auc: 0.8710 - lr: 1.0088e-04\n",
      "Epoch 9/20\n",
      "427/977 [============>.................] - ETA: 2:14 - loss: 0.4401 - accuracy: 0.7884 - auc: 0.8741"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=True,\n",
    "                                                     save_best_only=True)\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_accuracy\",\n",
    "                                                     factor = 0.7,\n",
    "                                                     patience = 5,\n",
    "                                                     min_lr = 10**-6,\n",
    "                                                     cooldown = 10)\n",
    "\n",
    "    history = History()\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=20,\n",
    "        batch_size=10240,\n",
    "        validation_data=(x_test,y_test),\n",
    "        callbacks=[cp_callback, reduce_lr, history, HostLog()]\n",
    "    )\n",
    "\n",
    "    model.save('ResNet_52')\n",
    "\n",
    "    with open(\"sunnyMamoni_m2.txt\", \"a\") as f:\n",
    "        f.write(str(history.history)+\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169ec50e",
   "metadata": {},
   "source": [
    "model.save('ResNet_52')\n",
    "\n",
    "with open(\"sunnyMamoni_m2.txt\", \"a\") as f:\n",
    "    f.write(str(history.history))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
